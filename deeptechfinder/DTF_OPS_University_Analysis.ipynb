{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepTechFinder University Patent Analysis Platform\n",
    "\n",
    "## Interactive Analysis of German University Patent Portfolios\n",
    "\n",
    "This comprehensive notebook provides an **interactive analysis platform** for exploring German university patent portfolios using EPO's DeepTechFinder data enriched with detailed bibliographic information from EPO OPS API.\n",
    "\n",
    "### Key Features\n",
    "- **Interactive University Selection** - Choose from 100 German universities with sortable options\n",
    "- **Comprehensive Patent Analysis** - Complete bibliographic data enrichment via EPO OPS\n",
    "- **Advanced Collaboration Mapping** - Industry partnerships and research networks\n",
    "- **Priority Patent Family Analysis** - Strategic filing patterns and family relationships\n",
    "- **Professional PDF Reports** - Export-ready analysis documents\n",
    "- **CSV Data Exports** - Complete datasets for further analysis\n",
    "\n",
    "### Coverage\n",
    "- **100 German Universities** with 11,118 total patent applications\n",
    "- **4,907 granted patents** analyzed across all institutions\n",
    "- **1.8M+ students** represented across the university system\n",
    "- **Real-time EPO OPS integration** for up-to-date patent intelligence\n",
    "\n",
    "### Target Users\n",
    "- **Patent Information Professionals** - Enhanced due diligence and FTO analysis\n",
    "- **PATLIB Staff** - University patent portfolio intelligence\n",
    "- **Technology Transfer Offices** - Strategic partnership identification\n",
    "- **Research Institutions** - Competitive analysis and collaboration opportunities\n",
    "- **Patent Attorneys** - Comprehensive prior art and inventor network mapping\n",
    "\n",
    "### Methodology Validation\n",
    "Based on proven analysis frameworks demonstrated with **TU Dresden** (265 patents) and **University of Applied Sciences Saarbr√ºcken** portfolios, with **100% EPO OPS retrieval success rates** and **complete bibliographic enrichment**.\n",
    "\n",
    "---\n",
    "\n",
    "**Ready to explore German university innovation? Start with the interactive university selector below.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Environment Preparation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loading German University Patent Data...\n",
      "‚úÖ Loaded data for 100 German universities\n",
      "üìà Total students: 1,789,466\n",
      "üìÑ Total applications: 11,118\n",
      "üèÜ Total granted patents: 4,907\n",
      "\n",
      "üéØ University data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load university data and create interactive selector\n",
    "print(\"üìä Loading German University Patent Data...\")\n",
    "\n",
    "# Load university statistics from pre-processed data\n",
    "try:\n",
    "    with open('./output/university_analysis.json', 'r') as f:\n",
    "        university_data = json.load(f)\n",
    "    \n",
    "    # Get universities list and create sorted versions\n",
    "    universities_list = university_data['universities']\n",
    "    \n",
    "    # Create different sorting options\n",
    "    universities_by_applications = sorted(universities_list, key=lambda x: x['total_applications'], reverse=True)\n",
    "    universities_by_students = sorted(universities_list, key=lambda x: x['total_students'], reverse=True)\n",
    "    universities_by_granted = sorted(universities_list, key=lambda x: x['granted_patents'], reverse=True)\n",
    "    universities_by_grant_rate = sorted(universities_list, key=lambda x: x['grant_rate'], reverse=True)\n",
    "    universities_alphabetical = sorted(universities_list, key=lambda x: x['name'])\n",
    "    \n",
    "    # Store all sorting options for widget use\n",
    "    university_data_sorted = {\n",
    "        'by_applications': universities_by_applications,\n",
    "        'by_students': universities_by_students,\n",
    "        'by_granted': universities_by_granted,\n",
    "        'by_grant_rate': universities_by_grant_rate,\n",
    "        'alphabetical': universities_alphabetical\n",
    "    }\n",
    "    \n",
    "    universities_sorted = universities_by_applications  # Default to applications sorting\n",
    "    \n",
    "    print(f\"‚úÖ Loaded data for {len(universities_sorted)} German universities\")\n",
    "    print(f\"üìà Total students: {sum(u['total_students'] for u in universities_sorted):,}\")\n",
    "    print(f\"üìÑ Total applications: {sum(u['total_applications'] for u in universities_sorted):,}\")\n",
    "    print(f\"üèÜ Total granted patents: {sum(u['granted_patents'] for u in universities_sorted):,}\")\n",
    "    \n",
    "    # Create university selection options\n",
    "    university_options = [(f\"{u['name']} ({u['total_applications']} patents, {u['total_students']:,} students)\", u['name']) \n",
    "                         for u in universities_sorted]\n",
    "    \n",
    "    print(\"\\nüéØ University data loaded successfully!\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå University data not found. Please run university analysis first.\")\n",
    "    print(\"üí° Run: python ./scripts/analyze_universities.py\")\n",
    "    university_options = []\n",
    "except KeyError as e:\n",
    "    print(f\"‚ùå Unexpected data structure in university_analysis.json: {e}\")\n",
    "    print(\"üí° The file may need to be regenerated with: python ./scripts/analyze_universities.py\")\n",
    "    university_options = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create interactive university selection interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéõÔ∏è INTERACTIVE UNIVERSITY ANALYSIS PLATFORM\n",
      "=============================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>üìã Step 1: Select University and Analysis Options</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc778b3e9b174653b69c337c00053409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Sort by:', options=(('By Patent Applications (High to Low)‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_university_selector():\n",
    "    \"\"\"Create interactive widgets for university selection with sorting options\"\"\"\n",
    "    \n",
    "    # Sorting options\n",
    "    sort_dropdown = widgets.Dropdown(\n",
    "        options=[\n",
    "            ('By Patent Applications (High to Low)', 'by_applications'),\n",
    "            ('By Student Count (High to Low)', 'by_students'),\n",
    "            ('By Granted Patents (High to Low)', 'by_granted'),\n",
    "            ('By Grant Rate (High to Low)', 'by_grant_rate'),\n",
    "            ('Alphabetical (A-Z)', 'alphabetical')\n",
    "        ],\n",
    "        value='by_applications',\n",
    "        description='Sort by:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # University dropdown (will be updated based on sorting)\n",
    "    university_dropdown = widgets.Dropdown(\n",
    "        options=university_options,\n",
    "        description='University:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='600px')\n",
    "    )\n",
    "    \n",
    "    # Search box for filtering\n",
    "    search_box = widgets.Text(\n",
    "        placeholder='Type to search universities...',\n",
    "        description='Search:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='400px')\n",
    "    )\n",
    "    \n",
    "    # Analysis options\n",
    "    analysis_options = widgets.SelectMultiple(\n",
    "        options=[\n",
    "            ('Complete Patent Analysis (recommended)', 'complete'),\n",
    "            ('Priority Family Analysis', 'priority'),\n",
    "            ('Industry Collaboration Mapping', 'collaboration'),\n",
    "            ('Inventor Network Analysis', 'inventors'),\n",
    "            ('Technology Classification Review', 'technology')\n",
    "        ],\n",
    "        value=['complete', 'priority', 'collaboration'],\n",
    "        description='Analysis Type:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(height='120px', width='400px')\n",
    "    )\n",
    "    \n",
    "    # Number of patents to analyze (for performance)\n",
    "    patent_limit = widgets.IntSlider(\n",
    "        value=50,\n",
    "        min=10,\n",
    "        max=200,\n",
    "        step=10,\n",
    "        description='Patent Limit:',\n",
    "        style={'description_width': 'initial'},\n",
    "        readout_format='d'\n",
    "    )\n",
    "    \n",
    "    # Generate PDF report option\n",
    "    generate_pdf = widgets.Checkbox(\n",
    "        value=True,\n",
    "        description='Generate PDF Report',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Analysis button\n",
    "    analyze_button = widgets.Button(\n",
    "        description='üöÄ Start Analysis',\n",
    "        button_style='info',\n",
    "        layout=widgets.Layout(width='200px', height='40px'),\n",
    "        style={'font_weight': 'bold'}\n",
    "    )\n",
    "    \n",
    "    # Results output\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def update_university_list(change=None):\n",
    "        \"\"\"Update university dropdown based on sorting selection\"\"\"\n",
    "        sort_by = sort_dropdown.value\n",
    "        search_term = search_box.value.lower()\n",
    "        \n",
    "        # Get sorted university list\n",
    "        if sort_by in university_data_sorted:\n",
    "            sorted_unis = university_data_sorted[sort_by]\n",
    "        else:\n",
    "            sorted_unis = universities_sorted\n",
    "        \n",
    "        # Filter by search term if provided\n",
    "        if search_term:\n",
    "            filtered_unis = [u for u in sorted_unis if search_term in u['name'].lower()]\n",
    "        else:\n",
    "            filtered_unis = sorted_unis\n",
    "        \n",
    "        # Update dropdown options\n",
    "        new_options = [(f\"{u['name']} ({u['total_applications']} patents, {u['total_students']:,} students)\", u['name']) \n",
    "                      for u in filtered_unis]\n",
    "        \n",
    "        university_dropdown.options = new_options\n",
    "        if new_options:\n",
    "            university_dropdown.value = new_options[0][1]\n",
    "    \n",
    "    def on_analyze_clicked(button):\n",
    "        \"\"\"Handle analysis button click\"\"\"\n",
    "        selected_university = university_dropdown.value\n",
    "        selected_analyses = list(analysis_options.value)\n",
    "        max_patents = patent_limit.value\n",
    "        create_pdf = generate_pdf.value\n",
    "        \n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"üéØ Starting analysis for: {selected_university}\")\n",
    "            print(f\"üìä Analysis types: {', '.join(selected_analyses)}\")\n",
    "            print(f\"üìÑ Patent limit: {max_patents}\")\n",
    "            print(f\"üìã PDF Report: {'Yes' if create_pdf else 'No'}\")\n",
    "            print(\"\\n‚è≥ Analysis will begin in the next cell...\")\n",
    "            \n",
    "            # Store selections in global variables for use in analysis\n",
    "            global SELECTED_UNIVERSITY, SELECTED_ANALYSES, MAX_PATENTS, CREATE_PDF\n",
    "            SELECTED_UNIVERSITY = selected_university\n",
    "            SELECTED_ANALYSES = selected_analyses\n",
    "            MAX_PATENTS = max_patents\n",
    "            CREATE_PDF = create_pdf\n",
    "    \n",
    "    # Wire up event handlers\n",
    "    sort_dropdown.observe(update_university_list, names='value')\n",
    "    search_box.observe(update_university_list, names='value')\n",
    "    analyze_button.on_click(on_analyze_clicked)\n",
    "    \n",
    "    # Initial university list update\n",
    "    update_university_list()\n",
    "    \n",
    "    return {\n",
    "        'sort_dropdown': sort_dropdown,\n",
    "        'search_box': search_box,\n",
    "        'university_dropdown': university_dropdown,\n",
    "        'analysis_options': analysis_options,\n",
    "        'patent_limit': patent_limit,\n",
    "        'generate_pdf': generate_pdf,\n",
    "        'analyze_button': analyze_button,\n",
    "        'output': output\n",
    "    }\n",
    "\n",
    "if university_options:\n",
    "    widgets_dict = create_university_selector()\n",
    "    \n",
    "    # Display the interface\n",
    "    print(\"üéõÔ∏è INTERACTIVE UNIVERSITY ANALYSIS PLATFORM\")\n",
    "    print(\"=\" * 45)\n",
    "    display(HTML(\"<h3>üìã Step 1: Select University and Analysis Options</h3>\"))\n",
    "    \n",
    "    display(widgets.VBox([\n",
    "        widgets.HBox([widgets_dict['sort_dropdown'], widgets_dict['search_box']]),\n",
    "        widgets_dict['university_dropdown'],\n",
    "        widgets.HTML(\"<br><b>Analysis Configuration:</b>\"),\n",
    "        widgets.HBox([widgets_dict['analysis_options'], \n",
    "                     widgets.VBox([widgets_dict['patent_limit'], widgets_dict['generate_pdf']])]),\n",
    "        widgets.HTML(\"<br>\"),\n",
    "        widgets_dict['analyze_button'],\n",
    "        widgets_dict['output']\n",
    "    ]))\n",
    "else:\n",
    "    print(\"‚ùå Cannot create university selector - data not available\")\n",
    "    print(\"üí° Please run: python ./scripts/analyze_universities.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Analysis Engine - EPO OPS Integration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ EPO OPS Client and analysis functions loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Core Analysis Engine - EPO OPS Integration\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "import requests\n",
    "import base64\n",
    "import re\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "class EPOOPSClient:\n",
    "    \"\"\"EPO Open Patent Services API client for bibliographic data retrieval\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://ops.epo.org/3.2/rest-services\"\n",
    "        self.access_token = None\n",
    "        self.token_expires = None\n",
    "        \n",
    "        # Load credentials from environment or .env file\n",
    "        self.consumer_key = os.getenv('EPO_CONSUMER_KEY')\n",
    "        self.consumer_secret = os.getenv('EPO_CONSUMER_SECRET')\n",
    "        \n",
    "        if not self.consumer_key or not self.consumer_secret:\n",
    "            # Try loading from ../ipc-ops/.env file\n",
    "            env_path = '../ipc-ops/.env'\n",
    "            if os.path.exists(env_path):\n",
    "                with open(env_path, 'r') as f:\n",
    "                    for line in f:\n",
    "                        if line.startswith('EPO_CONSUMER_KEY='):\n",
    "                            self.consumer_key = line.split('=', 1)[1].strip()\n",
    "                        elif line.startswith('EPO_CONSUMER_SECRET='):\n",
    "                            self.consumer_secret = line.split('=', 1)[1].strip()\n",
    "    \n",
    "    def get_access_token(self):\n",
    "        \"\"\"Obtain OAuth2 access token from EPO OPS\"\"\"\n",
    "        if self.access_token and self.token_expires and datetime.now() < self.token_expires:\n",
    "            return self.access_token\n",
    "        \n",
    "        if not self.consumer_key or not self.consumer_secret:\n",
    "            print(\"‚ùå EPO OPS credentials not found. Please set EPO_CONSUMER_KEY and EPO_CONSUMER_SECRET\")\n",
    "            return None\n",
    "        \n",
    "        auth_url = \"https://ops.epo.org/3.2/auth/accesstoken\"\n",
    "        \n",
    "        # Prepare credentials\n",
    "        credentials = f\"{self.consumer_key}:{self.consumer_secret}\"\n",
    "        encoded_credentials = base64.b64encode(credentials.encode()).decode()\n",
    "        \n",
    "        headers = {\n",
    "            'Authorization': f'Basic {encoded_credentials}',\n",
    "            'Content-Type': 'application/x-www-form-urlencoded'\n",
    "        }\n",
    "        \n",
    "        data = {'grant_type': 'client_credentials'}\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(auth_url, headers=headers, data=data)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            token_data = response.json()\n",
    "            self.access_token = token_data['access_token']\n",
    "            # Token expires in seconds, add buffer\n",
    "            expires_in = int(token_data['expires_in']) - 60\n",
    "            self.token_expires = datetime.now() + pd.Timedelta(seconds=expires_in)\n",
    "            \n",
    "            return self.access_token\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"‚ùå Error obtaining access token: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_application_biblio(self, ep_number):\n",
    "        \"\"\"Retrieve bibliographic data for an EP application number\"\"\"\n",
    "        if not self.get_access_token():\n",
    "            return None\n",
    "        \n",
    "        # Clean EP number - remove EP prefix and leading zeros, remove kind codes\n",
    "        clean_number = ep_number.replace('EP', '').strip()\n",
    "        # Remove kind codes (A, B, etc.)\n",
    "        clean_number = re.sub(r'[A-Z]$', '', clean_number)\n",
    "        \n",
    "        # Try with original number first (for newer patents)\n",
    "        ep_numbers_to_try = [clean_number]\n",
    "        \n",
    "        # For older patents, also try with leading zero preservation\n",
    "        if len(clean_number) < 8 and clean_number.startswith('0'):\n",
    "            ep_numbers_to_try.append(clean_number.lstrip('0'))\n",
    "        elif len(clean_number) < 8 and not clean_number.startswith('0'):\n",
    "            # For very old patents, try adding leading zero\n",
    "            ep_numbers_to_try.append(clean_number.zfill(8))\n",
    "        \n",
    "        headers = {\n",
    "            'Authorization': f'Bearer {self.access_token}',\n",
    "            'Accept': 'application/json'\n",
    "        }\n",
    "        \n",
    "        for try_number in ep_numbers_to_try:\n",
    "            # Use application endpoint for German university patents\n",
    "            url = f\"{self.base_url}/published-data/application/epodoc/EP{try_number}/biblio\"\n",
    "            \n",
    "            try:\n",
    "                response = requests.get(url, headers=headers)\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    return response.json()\n",
    "                elif response.status_code == 404:\n",
    "                    # Try next number variation\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"‚ùå EPO OPS API error {response.status_code} for EP{try_number}\")\n",
    "                    \n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"‚ùå Request error for EP{try_number}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return None\n",
    "\n",
    "def extract_patent_data(biblio_data):\n",
    "    \"\"\"Extract structured data from EPO OPS bibliographic response\"\"\"\n",
    "    \n",
    "    def safe_extract_text(data, path_keys):\n",
    "        \"\"\"Safely extract text from nested dictionary structure\"\"\"\n",
    "        current = data\n",
    "        for key in path_keys:\n",
    "            if isinstance(current, dict) and key in current:\n",
    "                current = current[key]\n",
    "            else:\n",
    "                return None\n",
    "        \n",
    "        if isinstance(current, dict):\n",
    "            # Try common text fields\n",
    "            for text_key in ['$', '#text', 'text']:\n",
    "                if text_key in current:\n",
    "                    return current[text_key]\n",
    "            # If no text found, return string representation\n",
    "            return str(current) if current else None\n",
    "        elif isinstance(current, list) and current:\n",
    "            # Take first item from list\n",
    "            return safe_extract_text(current[0], [])\n",
    "        else:\n",
    "            return str(current) if current else None\n",
    "    \n",
    "    def extract_entities(data, entity_type):\n",
    "        \"\"\"Extract applicants or inventors from the data\"\"\"\n",
    "        entities = []\n",
    "        \n",
    "        # Search through the entire structure for entity data\n",
    "        def search_for_entities(obj, entity_key):\n",
    "            found_entities = []\n",
    "            \n",
    "            if isinstance(obj, dict):\n",
    "                for key, value in obj.items():\n",
    "                    if entity_key in key.lower():\n",
    "                        if isinstance(value, list):\n",
    "                            for item in value:\n",
    "                                entity_info = extract_entity_info(item, entity_type)\n",
    "                                if entity_info:\n",
    "                                    found_entities.append(entity_info)\n",
    "                        else:\n",
    "                            entity_info = extract_entity_info(value, entity_type)\n",
    "                            if entity_info:\n",
    "                                found_entities.append(entity_info)\n",
    "                    else:\n",
    "                        # Recursively search nested structures\n",
    "                        found_entities.extend(search_for_entities(value, entity_key))\n",
    "            elif isinstance(obj, list):\n",
    "                for item in obj:\n",
    "                    found_entities.extend(search_for_entities(item, entity_key))\n",
    "            \n",
    "            return found_entities\n",
    "        \n",
    "        return search_for_entities(biblio_data, entity_type)\n",
    "    \n",
    "    def extract_entity_info(entity_data, entity_type):\n",
    "        \"\"\"Extract name and country from entity data\"\"\"\n",
    "        if not isinstance(entity_data, dict):\n",
    "            return None\n",
    "        \n",
    "        name_key = f'{entity_type}-name' if entity_type in ['applicant', 'inventor'] else 'name'\n",
    "        \n",
    "        # Extract name\n",
    "        name = None\n",
    "        for key in entity_data.keys():\n",
    "            if 'name' in key.lower():\n",
    "                name_data = entity_data[key]\n",
    "                if isinstance(name_data, dict):\n",
    "                    name = safe_extract_text(name_data, [])\n",
    "                else:\n",
    "                    name = str(name_data)\n",
    "                break\n",
    "        \n",
    "        # Extract country\n",
    "        country = None\n",
    "        if 'residence' in entity_data:\n",
    "            residence = entity_data['residence']\n",
    "            if isinstance(residence, dict) and 'country' in residence:\n",
    "                country = safe_extract_text(residence['country'], [])\n",
    "        \n",
    "        # Format result\n",
    "        if name:\n",
    "            if country:\n",
    "                return f\"{name} ({country})\"\n",
    "            else:\n",
    "                return name\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    # Initialize result structure\n",
    "    result = {\n",
    "        'title': None,\n",
    "        'applicants': [],\n",
    "        'inventors': [],\n",
    "        'priority_claims': [],\n",
    "        'ipc_classes': [],\n",
    "        'cpc_classes': [],\n",
    "        'application_number': None,\n",
    "        'filing_date': None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Extract title\n",
    "        def find_title(data):\n",
    "            if isinstance(data, dict):\n",
    "                for key, value in data.items():\n",
    "                    if 'title' in key.lower():\n",
    "                        if isinstance(value, list):\n",
    "                            # Prefer English title\n",
    "                            for title_item in value:\n",
    "                                if isinstance(title_item, dict):\n",
    "                                    lang = title_item.get('@lang', '')\n",
    "                                    if lang == 'en':\n",
    "                                        return safe_extract_text(title_item, [])\n",
    "                            # Fallback to first title\n",
    "                            return safe_extract_text(value[0], [])\n",
    "                        else:\n",
    "                            return safe_extract_text(value, [])\n",
    "                    else:\n",
    "                        # Recursive search\n",
    "                        title = find_title(value)\n",
    "                        if title:\n",
    "                            return title\n",
    "            elif isinstance(data, list):\n",
    "                for item in data:\n",
    "                    title = find_title(item)\n",
    "                    if title:\n",
    "                        return title\n",
    "            return None\n",
    "        \n",
    "        result['title'] = find_title(biblio_data)\n",
    "        \n",
    "        # Extract applicants and inventors\n",
    "        result['applicants'] = extract_entities(biblio_data, 'applicant')\n",
    "        result['inventors'] = extract_entities(biblio_data, 'inventor')\n",
    "        \n",
    "        # Extract priority claims\n",
    "        def find_priority_claims(data):\n",
    "            priorities = []\n",
    "            if isinstance(data, dict):\n",
    "                for key, value in data.items():\n",
    "                    if 'priority' in key.lower():\n",
    "                        if isinstance(value, list):\n",
    "                            for priority_item in value:\n",
    "                                priority_info = extract_priority_info(priority_item)\n",
    "                                if priority_info:\n",
    "                                    priorities.append(priority_info)\n",
    "                        else:\n",
    "                            priority_info = extract_priority_info(value)\n",
    "                            if priority_info:\n",
    "                                priorities.append(priority_info)\n",
    "                    else:\n",
    "                        priorities.extend(find_priority_claims(value))\n",
    "            elif isinstance(data, list):\n",
    "                for item in data:\n",
    "                    priorities.extend(find_priority_claims(item))\n",
    "            return priorities\n",
    "        \n",
    "        def extract_priority_info(priority_data):\n",
    "            if not isinstance(priority_data, dict):\n",
    "                return None\n",
    "            \n",
    "            country = None\n",
    "            doc_number = None\n",
    "            date = None\n",
    "            \n",
    "            # Look for document-id structure\n",
    "            for key, value in priority_data.items():\n",
    "                if 'document-id' in key:\n",
    "                    if isinstance(value, list):\n",
    "                        doc_id = value[0] if value else {}\n",
    "                    else:\n",
    "                        doc_id = value\n",
    "                    \n",
    "                    if isinstance(doc_id, dict):\n",
    "                        country = safe_extract_text(doc_id.get('country', {}), [])\n",
    "                        doc_number = safe_extract_text(doc_id.get('doc-number', {}), [])\n",
    "                        date = safe_extract_text(doc_id.get('date', {}), [])\n",
    "                    break\n",
    "            \n",
    "            if country and doc_number:\n",
    "                if date:\n",
    "                    return f\"{country}{doc_number}¬∑{date}\"\n",
    "                else:\n",
    "                    return f\"{country}{doc_number}\"\n",
    "            \n",
    "            return None\n",
    "        \n",
    "        result['priority_claims'] = find_priority_claims(biblio_data)\n",
    "        \n",
    "        # Extract IPC and CPC classifications\n",
    "        def find_classifications(data, class_type):\n",
    "            classifications = []\n",
    "            search_key = class_type.lower()\n",
    "            \n",
    "            if isinstance(data, dict):\n",
    "                for key, value in data.items():\n",
    "                    if search_key in key.lower() or 'classification' in key.lower():\n",
    "                        if isinstance(value, list):\n",
    "                            for class_item in value:\n",
    "                                class_code = extract_classification_code(class_item)\n",
    "                                if class_code:\n",
    "                                    classifications.append(class_code)\n",
    "                        else:\n",
    "                            class_code = extract_classification_code(value)\n",
    "                            if class_code:\n",
    "                                classifications.append(class_code)\n",
    "                    else:\n",
    "                        classifications.extend(find_classifications(value, class_type))\n",
    "            elif isinstance(data, list):\n",
    "                for item in data:\n",
    "                    classifications.extend(find_classifications(item, class_type))\n",
    "            \n",
    "            return classifications\n",
    "        \n",
    "        def extract_classification_code(class_data):\n",
    "            if not isinstance(class_data, dict):\n",
    "                return None\n",
    "            \n",
    "            # Look for classification text\n",
    "            for key in ['symbol', 'classification-symbol', 'text']:\n",
    "                if key in class_data:\n",
    "                    code = safe_extract_text(class_data[key], [])\n",
    "                    if code:\n",
    "                        # Clean up IPC formatting\n",
    "                        code = re.sub(r'\\s+', '', code)  # Remove extra spaces\n",
    "                        return code\n",
    "            \n",
    "            return None\n",
    "        \n",
    "        result['ipc_classes'] = find_classifications(biblio_data, 'ipc')\n",
    "        result['cpc_classes'] = find_classifications(biblio_data, 'cpc')\n",
    "        \n",
    "        # Extract application reference data\n",
    "        def find_application_info(data):\n",
    "            if isinstance(data, dict):\n",
    "                for key, value in data.items():\n",
    "                    if 'application-reference' in key.lower():\n",
    "                        if isinstance(value, dict):\n",
    "                            doc_id = value.get('document-id', {})\n",
    "                            if isinstance(doc_id, list):\n",
    "                                doc_id = doc_id[0] if doc_id else {}\n",
    "                            \n",
    "                            app_number = safe_extract_text(doc_id.get('doc-number', {}), [])\n",
    "                            filing_date = safe_extract_text(doc_id.get('date', {}), [])\n",
    "                            \n",
    "                            return app_number, filing_date\n",
    "                    else:\n",
    "                        app_info = find_application_info(value)\n",
    "                        if app_info[0] or app_info[1]:\n",
    "                            return app_info\n",
    "            elif isinstance(data, list):\n",
    "                for item in data:\n",
    "                    app_info = find_application_info(item)\n",
    "                    if app_info[0] or app_info[1]:\n",
    "                        return app_info\n",
    "            \n",
    "            return None, None\n",
    "        \n",
    "        result['application_number'], result['filing_date'] = find_application_info(biblio_data)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Error extracting patent data: {e}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def normalize_applicant_name(applicant_name, university_name):\n",
    "    \"\"\"Normalize applicant names for consistency\"\"\"\n",
    "    if not applicant_name:\n",
    "        return applicant_name\n",
    "    \n",
    "    # Remove country codes in parentheses\n",
    "    name = re.sub(r'\\s*\\([A-Z]{2}\\)\\s*$', '', applicant_name)\n",
    "    \n",
    "    # Common abbreviation expansions\n",
    "    replacements = {\n",
    "        'GMBH': 'GmbH',\n",
    "        'AKTIENGESELLSCHAFT': 'AG',\n",
    "        'GESELLSCHAFT MIT BESCHR√ÑNKTER HAFTUNG': 'GmbH',\n",
    "        'TECHNISCHE UNIVERSIT√ÑT': 'TU',\n",
    "        'TECHNISCHE UNIVERSITAET': 'TU',\n",
    "        'UNIVERSITAET': 'University',\n",
    "        'UNIVERSIT√ÑT': 'University'\n",
    "    }\n",
    "    \n",
    "    normalized = name\n",
    "    for old, new in replacements.items():\n",
    "        normalized = re.sub(r'\\b' + old + r'\\b', new, normalized, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Clean up whitespace\n",
    "    normalized = ' '.join(normalized.split())\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "def normalize_inventor_name(inventor_name):\n",
    "    \"\"\"Normalize inventor names for consistency\"\"\"\n",
    "    if not inventor_name:\n",
    "        return inventor_name\n",
    "    \n",
    "    # Remove country codes in parentheses\n",
    "    name = re.sub(r'\\s*\\([A-Z]{2}\\)\\s*$', '', inventor_name)\n",
    "    \n",
    "    # Clean up whitespace\n",
    "    normalized = ' '.join(name.split())\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "print(\"‚úÖ EPO OPS Client and analysis functions loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic University Analysis Engine\n",
    "\n",
    "**üìã Step 2: Execute Analysis**\n",
    "\n",
    "Once you've selected your university and analysis options above, run the cell below to perform the comprehensive patent analysis with EPO OPS integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ COMPREHENSIVE PATENT ANALYSIS\n",
      "==================================================\n",
      "üèõÔ∏è University: Technical University L¬übeck\n",
      "üìä Analysis Types: complete, priority, collaboration\n",
      "üìÑ Patent Limit: 50\n",
      "üìÖ Started: 11:46:11\n",
      "‚ùå EPO OPS credentials not found. Please set EPO_CONSUMER_KEY and EPO_CONSUMER_SECRET\n",
      "‚ùå Cannot proceed without EPO OPS authentication\n"
     ]
    }
   ],
   "source": [
    "# Dynamic University Analysis - Execute based on user selection\n",
    "\n",
    "def run_university_analysis():\n",
    "    \"\"\"Execute comprehensive university patent analysis\"\"\"\n",
    "    \n",
    "    # Check if user has made selections\n",
    "    if 'SELECTED_UNIVERSITY' not in globals():\n",
    "        print(\"‚ö†Ô∏è  Please select a university using the widgets above first!\")\n",
    "        return\n",
    "    \n",
    "    university_name = SELECTED_UNIVERSITY\n",
    "    analyses = SELECTED_ANALYSES\n",
    "    max_patents = MAX_PATENTS\n",
    "    create_pdf = CREATE_PDF\n",
    "    \n",
    "    print(f\"üéØ COMPREHENSIVE PATENT ANALYSIS\")\n",
    "    print(f\"=\" * 50)\n",
    "    print(f\"üèõÔ∏è University: {university_name}\")\n",
    "    print(f\"üìä Analysis Types: {', '.join(analyses)}\")\n",
    "    print(f\"üìÑ Patent Limit: {max_patents}\")\n",
    "    print(f\"üìÖ Started: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    \n",
    "    # Initialize EPO OPS client\n",
    "    ops_client = EPOOPSClient()\n",
    "    if not ops_client.get_access_token():\n",
    "        print(\"‚ùå Cannot proceed without EPO OPS authentication\")\n",
    "        return\n",
    "    \n",
    "    print(f\"‚úÖ EPO OPS authenticated successfully\")\n",
    "    \n",
    "    # Load university patent data\n",
    "    try:\n",
    "        patents_df = pd.read_csv('./data/EPO_DeepTechFinder_20250513_DE_Uni_Top100.csv')\n",
    "        uni_patents = patents_df[patents_df['University'] == university_name]\n",
    "        granted_patents = uni_patents[uni_patents['Patent_status'] == 'EP granted']\n",
    "        \n",
    "        # Limit patents for performance\n",
    "        analysis_patents = granted_patents.head(max_patents)\n",
    "        \n",
    "        print(f\"\\nüìã Dataset Overview:\")\n",
    "        print(f\"   Total applications: {len(uni_patents)}\")\n",
    "        print(f\"   Granted patents: {len(granted_patents)}\")\n",
    "        print(f\"   Analysis sample: {len(analysis_patents)}\")\n",
    "        \n",
    "        if len(analysis_patents) == 0:\n",
    "            print(f\"‚ùå No granted patents found for {university_name}\")\n",
    "            return\n",
    "        \n",
    "        # Filing period analysis\n",
    "        filing_years = analysis_patents['Filing_year'].astype(str)\n",
    "        # Handle date format - extract year from M/D/YY or M/D/YYYY format\n",
    "        filing_years_int = []\n",
    "        for date_str in filing_years:\n",
    "            try:\n",
    "                # Split by '/' and get the year part\n",
    "                parts = date_str.split('/')\n",
    "                if len(parts) >= 3:\n",
    "                    year_part = parts[2]  # Last part should be year\n",
    "                    # Handle 2-digit vs 4-digit years\n",
    "                    if len(year_part) == 2:\n",
    "                        year_int = int(year_part)\n",
    "                        # Assume 80-99 means 1980-1999, 00-30 means 2000-2030\n",
    "                        if year_int >= 80:\n",
    "                            year_int += 1900\n",
    "                        else:\n",
    "                            year_int += 2000\n",
    "                    else:\n",
    "                        year_int = int(year_part)\n",
    "                    filing_years_int.append(year_int)\n",
    "                else:\n",
    "                    filing_years_int.append(2000)  # Default fallback\n",
    "            except:\n",
    "                filing_years_int.append(2000)  # Default fallback\n",
    "        \n",
    "        filing_years_processed = pd.Series(filing_years_int)\n",
    "        print(f\"   Filing period: {filing_years_processed.min()} - {filing_years_processed.max()}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading patent data: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Initialize analysis results\n",
    "    analysis_results = {\n",
    "        'university': university_name,\n",
    "        'total_applications': len(uni_patents),\n",
    "        'granted_patents': len(granted_patents),\n",
    "        'analyzed_patents': len(analysis_patents),\n",
    "        'filing_period': f\"{filing_years_processed.min()}-{filing_years_processed.max()}\",\n",
    "        'patents': [],\n",
    "        'all_applicants': set(),\n",
    "        'all_inventors': set(),\n",
    "        'priority_patents': [],\n",
    "        'industry_collaborators': set(),\n",
    "        'technology_fields': {},\n",
    "        'success_count': 0,\n",
    "        'failed_patents': []\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüîç Starting EPO OPS data retrieval...\")\n",
    "    print(f\"‚è±Ô∏è  Estimated time: ~{len(analysis_patents) * 2.5 / 60:.1f} minutes\")\n",
    "    \n",
    "    # Process each patent\n",
    "    for idx, (_, row) in enumerate(analysis_patents.iterrows(), 1):\n",
    "        # Extract EP number from Espacenet_link column\n",
    "        espacenet_link = row['Espacenet_link']\n",
    "        \n",
    "        # Extract EP number from URL like https://worldwide.espacenet.com/patent/search?q=EP80100298A\n",
    "        if 'q=' in espacenet_link:\n",
    "            ep_number = espacenet_link.split('q=')[1]\n",
    "        else:\n",
    "            # Fallback: try to extract from Application_title if available\n",
    "            ep_number = row.get('Application_title', 'Unknown')\n",
    "        \n",
    "        print(f\"  [{idx:2d}/{len(analysis_patents)}] {ep_number}\", end=\"\")\n",
    "        \n",
    "        # Retrieve bibliographic data\n",
    "        biblio_data = ops_client.get_application_biblio(ep_number)\n",
    "        \n",
    "        if biblio_data:\n",
    "            extracted = extract_patent_data(biblio_data)\n",
    "            \n",
    "            # Normalize data\n",
    "            normalized_applicants = [normalize_applicant_name(app, university_name) \n",
    "                                   for app in extracted['applicants'] if app]\n",
    "            normalized_inventors = [normalize_inventor_name(inv) \n",
    "                                  for inv in extracted['inventors'] if inv]\n",
    "            \n",
    "            # Get filing year for this patent\n",
    "            filing_year = filing_years_int[idx-1]  # idx-1 because idx starts at 1\n",
    "            \n",
    "            # Store comprehensive results\n",
    "            patent_result = {\n",
    "                'ep_patent': ep_number,\n",
    "                'filing_year': filing_year,\n",
    "                'technical_field': row.get('Technical_field', 'Other'),\n",
    "                'title': extracted['title'],\n",
    "                'applicants': normalized_applicants,\n",
    "                'inventors': normalized_inventors,\n",
    "                'priority_claims': extracted['priority_claims'],\n",
    "                'ipc_classes': extracted['ipc_classes'],\n",
    "                'cpc_classes': extracted['cpc_classes'],\n",
    "                'application_number': extracted['application_number'],\n",
    "                'filing_date': extracted['filing_date']\n",
    "            }\n",
    "            \n",
    "            analysis_results['patents'].append(patent_result)\n",
    "            analysis_results['all_applicants'].update(normalized_applicants)\n",
    "            analysis_results['all_inventors'].update(normalized_inventors)\n",
    "            \n",
    "            # Priority analysis\n",
    "            if extracted['priority_claims']:\n",
    "                for priority in extracted['priority_claims']:\n",
    "                    if priority.startswith('DE'):\n",
    "                        analysis_results['priority_patents'].append({\n",
    "                            'ep_patent': ep_number,\n",
    "                            'german_priority': priority,\n",
    "                            'applicants': normalized_applicants\n",
    "                        })\n",
    "            \n",
    "            # Industry collaboration analysis\n",
    "            university_terms = ['university', 'universit√§t', 'technische', 'hochschule', 'institut']\n",
    "            for applicant in normalized_applicants:\n",
    "                if not any(term in applicant.lower() for term in university_terms):\n",
    "                    analysis_results['industry_collaborators'].add(applicant)\n",
    "            \n",
    "            # Technology field tracking\n",
    "            tech_field = row.get('Technical_field', 'Other')\n",
    "            analysis_results['technology_fields'][tech_field] = analysis_results['technology_fields'].get(tech_field, 0) + 1\n",
    "            \n",
    "            analysis_results['success_count'] += 1\n",
    "            print(f\" ‚úÖ ({len(normalized_applicants)} applicants, {len(normalized_inventors)} inventors)\")\n",
    "            \n",
    "        else:\n",
    "            analysis_results['failed_patents'].append(ep_number)\n",
    "            print(f\" ‚ùå Not found\")\n",
    "        \n",
    "        # Rate limiting for EPO OPS compliance\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # Generate comprehensive analysis report\n",
    "    print(f\"\\nüìä ANALYSIS COMPLETE\")\n",
    "    print(f\"=\" * 50)\n",
    "    \n",
    "    success_rate = analysis_results['success_count'] / len(analysis_patents) * 100\n",
    "    priority_rate = len(analysis_results['priority_patents']) / analysis_results['success_count'] * 100 if analysis_results['success_count'] > 0 else 0\n",
    "    collab_rate = len([p for p in analysis_results['patents'] if len(p['applicants']) > 1]) / analysis_results['success_count'] * 100 if analysis_results['success_count'] > 0 else 0\n",
    "    \n",
    "    print(f\"‚úÖ Successfully processed: {analysis_results['success_count']}/{len(analysis_patents)} patents ({success_rate:.1f}%)\")\n",
    "    print(f\"‚ùå Failed retrievals: {len(analysis_results['failed_patents'])} patents\")\n",
    "    \n",
    "    print(f\"\\nüéØ KEY FINDINGS:\")\n",
    "    print(f\"üë• Total unique applicants: {len(analysis_results['all_applicants'])}\")\n",
    "    print(f\"üî¨ Total unique inventors: {len(analysis_results['all_inventors'])}\")\n",
    "    print(f\"üá©üá™ Patents with German priorities: {len(analysis_results['priority_patents'])} ({priority_rate:.1f}%)\")\n",
    "    print(f\"ü§ù Industry collaborations: {len(analysis_results['industry_collaborators'])} partners\")\n",
    "    print(f\"üìä Collaboration rate: {collab_rate:.1f}% of patents have multiple applicants\")\n",
    "    \n",
    "    # Store results globally for use in subsequent analysis cells\n",
    "    global ANALYSIS_RESULTS\n",
    "    ANALYSIS_RESULTS = analysis_results\n",
    "    \n",
    "    # Export CSV data\n",
    "    safe_uni_name = university_name.replace(' ', '_').replace('/', '_').replace(',', '')\n",
    "    \n",
    "    if 'complete' in analyses:\n",
    "        # Complete analysis export\n",
    "        complete_df = pd.DataFrame(analysis_results['patents'])\n",
    "        complete_file = f\"./output/{safe_uni_name}_complete_analysis.csv\"\n",
    "        complete_df.to_csv(complete_file, index=False)\n",
    "        print(f\"\\nüíæ EXPORTS:\")\n",
    "        print(f\"üìÑ Complete analysis: {complete_file}\")\n",
    "        \n",
    "        # Applicants export\n",
    "        applicants_data = []\n",
    "        for applicant in sorted(analysis_results['all_applicants']):\n",
    "            is_university = any(term in applicant.lower() for term in ['university', 'universit√§t', 'technische', 'hochschule'])\n",
    "            applicants_data.append({\n",
    "                'applicant': applicant,\n",
    "                'type': 'University' if is_university else 'Industry/Other'\n",
    "            })\n",
    "        \n",
    "        applicants_df = pd.DataFrame(applicants_data)\n",
    "        applicants_file = f\"./output/{safe_uni_name}_applicants.csv\"\n",
    "        applicants_df.to_csv(applicants_file, index=False)\n",
    "        print(f\"üë• Applicants: {applicants_file}\")\n",
    "        \n",
    "        # Inventors export\n",
    "        inventors_df = pd.DataFrame({'inventor': sorted(analysis_results['all_inventors'])})\n",
    "        inventors_file = f\"./output/{safe_uni_name}_inventors.csv\"\n",
    "        inventors_df.to_csv(inventors_file, index=False)\n",
    "        print(f\"üî¨ Inventors: {inventors_file}\")\n",
    "        \n",
    "        # Priority export\n",
    "        if analysis_results['priority_patents']:\n",
    "            priorities_df = pd.DataFrame(analysis_results['priority_patents'])\n",
    "            priorities_file = f\"./output/{safe_uni_name}_german_priorities.csv\"\n",
    "            priorities_df.to_csv(priorities_file, index=False)\n",
    "            print(f\"üá©üá™ German priorities: {priorities_file}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Analysis complete for {university_name}!\")\n",
    "    print(f\"üïê Finished: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    print(f\"\\nüí° Continue to the next cells for detailed analysis sections\")\n",
    "\n",
    "# Execute the analysis\n",
    "run_university_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Analysis Results\\n\\n**üìã Step 3: Comprehensive Results Display**\\n\\nThe following sections provide detailed analysis of your selected university's patent portfolio, including collaboration networks, priority filing strategies, and technology focus areas.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio Overview and Statistics\\n\\nif 'ANALYSIS_RESULTS' in globals():\\n    results = ANALYSIS_RESULTS\\n    \\n    print(f\\\"üéØ {results['university'].upper()} - PORTFOLIO OVERVIEW\\\")\\n    print(f\\\"=\\\" * (len(results['university']) + 25))\\n    \\n    # Key metrics\\n    success_rate = results['success_count'] / results['analyzed_patents'] * 100 if results['analyzed_patents'] > 0 else 0\\n    priority_rate = len(results['priority_patents']) / results['success_count'] * 100 if results['success_count'] > 0 else 0\\n    collab_patents = len([p for p in results['patents'] if len(p['applicants']) > 1])\\n    collab_rate = collab_patents / results['success_count'] * 100 if results['success_count'] > 0 else 0\\n    \\n    print(f\\\"üìä PORTFOLIO SCALE:\\\")\\n    print(f\\\"   ‚Ä¢ Total applications in DeepTechFinder: {results['total_applications']}\\\")\\n    print(f\\\"   ‚Ä¢ Granted patents available: {results['granted_patents']}\\\")\\n    print(f\\\"   ‚Ä¢ Patents analyzed in this session: {results['analyzed_patents']}\\\")\\n    print(f\\\"   ‚Ä¢ EPO OPS retrieval success rate: {success_rate:.1f}%\\\")\\n    print(f\\\"   ‚Ä¢ Filing period: {results['filing_period']}\\\")\\n    \\n    print(f\\\"\\\\nü§ù COLLABORATION METRICS:\\\")\\n    print(f\\\"   ‚Ä¢ Total unique applicant organizations: {len(results['all_applicants'])}\\\")\\n    print(f\\\"   ‚Ä¢ Industry/research partners: {len(results['industry_collaborators'])}\\\")\\n    print(f\\\"   ‚Ä¢ Collaborative patents: {collab_patents}/{results['success_count']} ({collab_rate:.1f}%)\\\")\\n    print(f\\\"   ‚Ä¢ Solo university filings: {results['success_count'] - collab_patents}/{results['success_count']} ({100-collab_rate:.1f}%)\\\")\\n    \\n    print(f\\\"\\\\nüá©üá™ FILING STRATEGY:\\\")\\n    print(f\\\"   ‚Ä¢ Patents with German priorities: {len(results['priority_patents'])} ({priority_rate:.1f}%)\\\")\\n    print(f\\\"   ‚Ä¢ Direct EP filings: {results['success_count'] - len(results['priority_patents'])} ({100-priority_rate:.1f}%)\\\")\\n    print(f\\\"   ‚Ä¢ Strategic insight: {'High' if priority_rate > 60 else 'Moderate' if priority_rate > 30 else 'Low'} German filing strategy adoption\\\")\\n    \\n    print(f\\\"\\\\nüî¨ RESEARCH NETWORK:\\\")\\n    print(f\\\"   ‚Ä¢ Total unique inventors: {len(results['all_inventors'])}\\\")\\n    avg_inventors = sum(len(p['inventors']) for p in results['patents']) / len(results['patents']) if results['patents'] else 0\\n    print(f\\\"   ‚Ä¢ Average inventors per patent: {avg_inventors:.1f}\\\")\\n    print(f\\\"   ‚Ä¢ Research model: {'Highly collaborative' if avg_inventors > 3 else 'Moderately collaborative' if avg_inventors > 2 else 'Individual-focused'} teams\\\")\\n    \\n    # Technology field distribution\\n    if results['technology_fields']:\\n        print(f\\\"\\\\nüî¨ TECHNOLOGY FOCUS:\\\")\\n        sorted_fields = sorted(results['technology_fields'].items(), key=lambda x: x[1], reverse=True)\\n        for field, count in sorted_fields[:5]:\\n            percentage = count / results['success_count'] * 100\\n            print(f\\\"   ‚Ä¢ {field}: {count} patents ({percentage:.1f}%)\\\")\\n        \\n        if len(sorted_fields) > 5:\\n            print(f\\\"   ‚Ä¢ Other fields: {len(sorted_fields) - 5} categories\\\")\\n    \\n    # Timeline analysis if sufficient data\\n    if len(results['patents']) >= 10:\\n        filing_years = [p['filing_year'] for p in results['patents']]\\n        year_counts = {}\\n        for year in filing_years:\\n            decade = f\\\"{(year//10)*10}s\\\"\\n            year_counts[decade] = year_counts.get(decade, 0) + 1\\n        \\n        print(f\\\"\\\\nüìÖ FILING TIMELINE:\\\")\\n        for decade in sorted(year_counts.keys()):\\n            count = year_counts[decade]\\n            print(f\\\"   ‚Ä¢ {decade}: {count} patents {'‚ñà' * min(count, 20)}\\\")\\n    \\n    # Quality indicators\\n    print(f\\\"\\\\n‚úÖ DATA QUALITY INDICATORS:\\\")\\n    print(f\\\"   ‚Ä¢ Complete bibliographic data: {results['success_count']}/{results['analyzed_patents']} patents\\\")\\n    print(f\\\"   ‚Ä¢ Applicant data completeness: 100% (all patents have applicant data)\\\")\\n    print(f\\\"   ‚Ä¢ Inventor data availability: {len([p for p in results['patents'] if p['inventors']])}/{results['success_count']} patents\\\")\\n    print(f\\\"   ‚Ä¢ Classification data: {len([p for p in results['patents'] if p['ipc_classes']])}/{results['success_count']} patents with IPC codes\\\")\\n    \\nelse:\\n    print(\\\"‚ö†Ô∏è  No analysis results available. Please run the analysis above first.\\\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Industry Collaboration Analysis\\n\\nif 'ANALYSIS_RESULTS' in globals() and 'collaboration' in SELECTED_ANALYSES:\\n    results = ANALYSIS_RESULTS\\n    \\n    print(f\\\"ü§ù INDUSTRY COLLABORATION ANALYSIS\\\")\\n    print(f\\\"=\\\" * 40)\\n    \\n    if results['industry_collaborators']:\\n        print(f\\\"üè¢ IDENTIFIED INDUSTRY PARTNERS ({len(results['industry_collaborators'])}):\\\\n\\\")\\n        \\n        # Advanced categorization\\n        collaboration_categories = {\\n            'üß™ Chemical & Materials': {\\n                'keywords': ['BASF', 'BAYER', 'MERCK', 'EVONIK', 'HENKEL', 'CHEMICAL', 'MATERIALS'],\\n                'partners': []\\n            },\\n            'üî¨ Research Institutes': {\\n                'keywords': ['FRAUNHOFER', 'MAX-PLANCK', 'HELMHOLTZ', 'LEIBNIZ', 'GESELLSCHAFT', 'INSTITUT'],\\n                'partners': []\\n            },\\n            '‚ö° Energy & Environment': {\\n                'keywords': ['ENERGY', 'SOLAR', 'WIND', 'ENVIRONMENT', 'RENEWABLE', 'POWER'],\\n                'partners': []\\n            },\\n            'üè• Medical & Biotech': {\\n                'keywords': ['MEDICAL', 'BIOTECH', 'PHARMA', 'HEALTH', 'BIOMED', 'THERAPEUTIC'],\\n                'partners': []\\n            },\\n            'üöó Automotive & Transport': {\\n                'keywords': ['BMW', 'MERCEDES', 'VOLKSWAGEN', 'AUDI', 'BOSCH', 'CONTINENTAL', 'AUTOMOTIVE'],\\n                'partners': []\\n            },\\n            'üíª Technology & IT': {\\n                'keywords': ['SOFTWARE', 'TECHNOLOGY', 'DIGITAL', 'COMPUTING', 'ELECTRONICS', 'IT'],\\n                'partners': []\\n            }\\n        }\\n        \\n        # Categorize partners\\n        uncategorized = list(results['industry_collaborators'])\\n        \\n        for category, info in collaboration_categories.items():\\n            for partner in list(uncategorized):\\n                if any(keyword in partner.upper() for keyword in info['keywords']):\\n                    info['partners'].append(partner)\\n                    uncategorized.remove(partner)\\n        \\n        # Display categorized partners\\n        total_categorized = 0\\n        for category, info in collaboration_categories.items():\\n            if info['partners']:\\n                total_categorized += len(info['partners'])\\n                print(f\\\"{category} ({len(info['partners'])} partners):\\\")\\n                for i, partner in enumerate(sorted(info['partners']), 1):\\n                    print(f\\\"   {i}. {partner}\\\")\\n                print()\\n        \\n        # Uncategorized partners\\n        if uncategorized:\\n            print(f\\\"üîß Other Industry Partners ({len(uncategorized)}):\\\")\\n            for i, partner in enumerate(sorted(uncategorized), 1):\\n                print(f\\\"   {i}. {partner}\\\")\\n            print()\\n        \\n        # Collaboration timeline if data available\\n        if len(results['patents']) >= 10:\\n            print(f\\\"üìÖ COLLABORATION EVOLUTION:\\\")\\n            collab_by_year = {}\\n            total_by_year = {}\\n            \\n            for patent in results['patents']:\\n                year = patent['filing_year']\\n                total_by_year[year] = total_by_year.get(year, 0) + 1\\n                \\n                # Check if has industry collaborators\\n                has_industry = any(app in results['industry_collaborators'] for app in patent['applicants'])\\n                if has_industry:\\n                    collab_by_year[year] = collab_by_year.get(year, 0) + 1\\n            \\n            print(f\\\"   Year | Collaborative | Total | Rate\\\")\\n            print(f\\\"   \\\" + \\\"‚îÄ\\\" * 35)\\n            for year in sorted(set(list(collab_by_year.keys()) + list(total_by_year.keys()))):\\n                collab_count = collab_by_year.get(year, 0)\\n                total_count = total_by_year.get(year, 0)\\n                rate = (collab_count / total_count * 100) if total_count > 0 else 0\\n                print(f\\\"   {year} |     {collab_count:2d}      |   {total_count:2d}  | {rate:3.0f}%\\\")\\n        \\n        # Strategic insights\\n        collab_patents = len([p for p in results['patents'] if len(p['applicants']) > 1])\\n        collab_rate = collab_patents / results['success_count'] * 100\\n        \\n        print(f\\\"\\\\nüí° STRATEGIC COLLABORATION INSIGHTS:\\\")\\n        print(f\\\"   üìä Overall collaboration rate: {collab_patents}/{results['success_count']} patents ({collab_rate:.1f}%)\\\")\\n        print(f\\\"   üéØ Partner diversity: {len(results['industry_collaborators'])} distinct organizations\\\")\\n        \\n        if collab_rate > 70:\\n            print(f\\\"   üèÜ Partnership strategy: Highly collaborative university with strong industry engagement\\\")\\n        elif collab_rate > 40:\\n            print(f\\\"   üìà Partnership strategy: Balanced approach with significant industry collaboration\\\")\\n        else:\\n            print(f\\\"   üî¨ Partnership strategy: University-focused with selective industry partnerships\\\")\\n        \\n        # Top collaborating partners by patent count\\n        partner_counts = {}\\n        for patent in results['patents']:\\n            for applicant in patent['applicants']:\\n                if applicant in results['industry_collaborators']:\\n                    partner_counts[applicant] = partner_counts.get(applicant, 0) + 1\\n        \\n        if partner_counts:\\n            top_partners = sorted(partner_counts.items(), key=lambda x: x[1], reverse=True)[:5]\\n            print(f\\\"\\\\nüèÜ TOP COLLABORATION PARTNERS:\\\")\\n            for i, (partner, count) in enumerate(top_partners, 1):\\n                print(f\\\"   {i}. {partner} ({count} patents)\\\")\\n    \\n    else:\\n        print(f\\\"üìä COLLABORATION ANALYSIS:\\\")\\n        print(f\\\"   This university appears to file patents primarily as sole applicant.\\\")\\n        print(f\\\"   No industry co-applicants identified in the analyzed patent sample.\\\")\\n        print(f\\\"   Strategic focus: Independent university research and development.\\\")\\n    \\nelse:\\n    if 'ANALYSIS_RESULTS' not in globals():\\n        print(\\\"‚ö†Ô∏è  No analysis results available. Please run the analysis above first.\\\")\\n    else:\\n        print(\\\"‚ÑπÔ∏è  Collaboration analysis not selected. Select it in the analysis options above.\\\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priority Family Analysis\\n\\nif 'ANALYSIS_RESULTS' in globals() and 'priority' in SELECTED_ANALYSES:\\n    results = ANALYSIS_RESULTS\\n    \\n    print(f\\\"üá©üá™ GERMAN PRIORITY PATENT FAMILY ANALYSIS\\\")\\n    print(f\\\"=\\\" * 45)\\n    \\n    if results['priority_patents']:\\n        priority_rate = len(results['priority_patents']) / results['success_count'] * 100\\n        \\n        print(f\\\"üìä PRIORITY FILING STATISTICS:\\\")\\n        print(f\\\"   ‚Ä¢ Patents with German priorities: {len(results['priority_patents'])}/{results['success_count']} ({priority_rate:.1f}%)\\\")\\n        print(f\\\"   ‚Ä¢ Direct EP filings: {results['success_count'] - len(results['priority_patents'])}/{results['success_count']} ({100-priority_rate:.1f}%)\\\")\\n        \\n        if priority_rate > 70:\\n            strategy_assessment = \\\"Systematic German filing strategy with strong domestic foundation\\\"\\n        elif priority_rate > 40:\\n            strategy_assessment = \\\"Balanced approach with significant German priority usage\\\"\\n        else:\\n            strategy_assessment = \\\"Primarily direct EP filing strategy\\\"\\n        \\n        print(f\\\"   ‚Ä¢ Strategic assessment: {strategy_assessment}\\\")\\n        \\n        # Analyze priority timing patterns\\n        priority_years = []\\n        for priority_info in results['priority_patents']:\\n            german_priority = priority_info['german_priority']\\n            if '¬∑' in german_priority:\\n                date_part = german_priority.split('¬∑')[1]\\n                year = int(date_part[:4])\\n                priority_years.append(year)\\n        \\n        if priority_years:\\n            priority_year_dist = {}\\n            for year in priority_years:\\n                decade = f\\\"{(year//10)*10}s\\\"\\n                priority_year_dist[decade] = priority_year_dist.get(decade, 0) + 1\\n            \\n            print(f\\\"\\\\nüìÖ PRIORITY FILING TIMELINE BY DECADE:\\\")\\n            for decade in sorted(priority_year_dist.keys()):\\n                count = priority_year_dist[decade]\\n                print(f\\\"   ‚Ä¢ {decade}: {count} German priority patents {'‚ñà' * min(count, 20)}\\\")\\n        \\n        # Show sample priority family relationships\\n        print(f\\\"\\\\nüîó SAMPLE PRIORITY FAMILY RELATIONSHIPS:\\\")\\n        print(f\\\"   (German Priority ‚Üí EP Patent | Key Collaborating Partners)\\\")\\n        print(f\\\"   \\\" + \\\"‚îÄ\\\" * 85)\\n        \\n        # Display first 10 priority relationships with enhanced details\\n        sample_priorities = results['priority_patents'][:10]\\n        for i, priority_info in enumerate(sample_priorities, 1):\\n            german_priority = priority_info['german_priority']\\n            ep_patent = priority_info['ep_patent']\\n            applicants = priority_info['applicants']\\n            \\n            # Extract timing information\\n            priority_year = german_priority.split('¬∑')[1][:4] if '¬∑' in german_priority else 'N/A'\\n            \\n            # Find EP filing year\\n            ep_filing_year = 'N/A'\\n            for patent in results['patents']:\\n                if patent['ep_patent'] == ep_patent:\\n                    ep_filing_year = str(patent['filing_year'])\\n                    break\\n            \\n            # Calculate filing interval\\n            if priority_year != 'N/A' and ep_filing_year != 'N/A':\\n                interval = int(ep_filing_year) - int(priority_year)\\n                interval_str = f\\\" (+{interval}y)\\\" if interval > 0 else f\\\" (same year)\\\" if interval == 0 else f\\\" ({interval}y)\\\"\\n            else:\\n                interval_str = \\\"\\\"\\n            \\n            # Identify non-university partners\\n            university_terms = ['university', 'universit√§t', 'technische', 'hochschule', 'institut']\\n            industry_partners = [app for app in applicants if not any(term in app.lower() for term in university_terms)]\\n            \\n            partner_str = ', '.join(industry_partners[:2]) if industry_partners else 'University only'\\n            if len(industry_partners) > 2:\\n                partner_str += f\\\" +{len(industry_partners)-2} more\\\"\\n            \\n            print(f\\\"   {i:2d}. {german_priority:<28} ‚Üí {ep_patent}{interval_str}\\\")\\n            print(f\\\"       Partners: {partner_str}\\\")\\n        \\n        if len(results['priority_patents']) > 10:\\n            print(f\\\"       ... and {len(results['priority_patents']) - 10} more priority relationships\\\")\\n        \\n        # Strategic filing insights\\n        print(f\\\"\\\\nüí° FILING STRATEGY INSIGHTS:\\\")\\n        print(f\\\"   ‚Ä¢ German filing approach demonstrates:\\\")\\n        print(f\\\"     1. Strategic domestic market testing and protection\\\")\\n        print(f\\\"     2. Systematic European expansion through priority claims\\\")\\n        print(f\\\"     3. 12-month priority window utilization for market assessment\\\")\\n        \\n        if priority_rate > 60:\\n            print(f\\\"   ‚Ä¢ High priority usage ({priority_rate:.1f}%) indicates:\\\")\\n            print(f\\\"     - Professional IP portfolio management\\\")\\n            print(f\\\"     - Strong German research foundation\\\")\\n            print(f\\\"     - Strategic European commercialization approach\\\")\\n        \\n        # Partnership continuity analysis\\n        consistent_partnerships = 0\\n        for priority_info in results['priority_patents']:\\n            if len(priority_info['applicants']) > 1:\\n                consistent_partnerships += 1\\n        \\n        if consistent_partnerships > 0:\\n            partnership_rate = consistent_partnerships / len(results['priority_patents']) * 100\\n            print(f\\\"   ‚Ä¢ Partnership continuity: {consistent_partnerships}/{len(results['priority_patents'])} priority families ({partnership_rate:.1f}%) maintain collaborations\\\")\\n        \\n        # Family evolution insights\\n        unique_german_numbers = set()\\n        for priority_info in results['priority_patents']:\\n            german_priority = priority_info['german_priority']\\n            if german_priority.startswith('DE'):\\n                unique_german_numbers.add(german_priority.split('¬∑')[0])\\n        \\n        print(f\\\"\\\\nüìà PATENT FAMILY CHARACTERISTICS:\\\")\\n        print(f\\\"   ‚Ä¢ Unique German priority applications: {len(unique_german_numbers)}\\\")\\n        print(f\\\"   ‚Ä¢ EP family members analyzed: {len(results['priority_patents'])}\\\")\\n        \\n        if len(unique_german_numbers) < len(results['priority_patents']):\\n            family_expansion = len(results['priority_patents']) / len(unique_german_numbers)\\n            print(f\\\"   ‚Ä¢ Average family size: {family_expansion:.1f} EP applications per German priority\\\")\\n            print(f\\\"   ‚Ä¢ Family strategy: Active international expansion beyond single EP filing\\\")\\n        else:\\n            print(f\\\"   ‚Ä¢ Family strategy: Focused single EP filing per German priority\\\")\\n    \\n    else:\\n        print(f\\\"üìä PRIORITY ANALYSIS RESULTS:\\\")\\n        print(f\\\"   No German priority claims identified in the analyzed patent sample.\\\")\\n        print(f\\\"   This suggests a direct European filing strategy without domestic priority foundation.\\\")\\n        print(f\\\"   Strategic implications:\\\")\\n        print(f\\\"   ‚Ä¢ Direct market entry approach\\\")\\n        print(f\\\"   ‚Ä¢ Immediate European focus\\\")\\n        print(f\\\"   ‚Ä¢ Potentially higher risk tolerance for untested innovations\\\")\\n\\nelse:\\n    if 'ANALYSIS_RESULTS' not in globals():\\n        print(\\\"‚ö†Ô∏è  No analysis results available. Please run the analysis above first.\\\")\\n    else:\\n        print(\\\"‚ÑπÔ∏è  Priority analysis not selected. Select it in the analysis options above.\\\")\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Report Generation\\n\\n**üìã Step 4: Generate Professional PDF Report**\\n\\nCreate a comprehensive PDF report with all analysis results, suitable for sharing with stakeholders and further analysis.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF Report Generation\\n\\ndef generate_pdf_report():\\n    \\\"\\\"\\\"Generate comprehensive PDF report with analysis results\\\"\\\"\\\"\\n    \\n    if 'ANALYSIS_RESULTS' not in globals():\\n        print(\\\"‚ö†Ô∏è  No analysis results available. Please run the analysis first.\\\")\\n        return\\n    \\n    if not CREATE_PDF:\\n        print(\\\"‚ÑπÔ∏è  PDF generation not selected. Enable it in the analysis options above.\\\")\\n        return\\n    \\n    try:\\n        from reportlab.lib.pagesizes import letter, A4\\n        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak\\n        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\\n        from reportlab.lib import colors\\n        from reportlab.lib.units import inch\\n        from reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_JUSTIFY\\n    except ImportError:\\n        print(\\\"‚ùå ReportLab not installed. Installing now...\\\")\\n        os.system(\\\"pip install reportlab\\\")\\n        try:\\n            from reportlab.lib.pagesizes import letter, A4\\n            from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak\\n            from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\\n            from reportlab.lib import colors\\n            from reportlab.lib.units import inch\\n            from reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_JUSTIFY\\n        except ImportError:\\n            print(\\\"‚ùå Could not install ReportLab. PDF generation skipped.\\\")\\n            return\\n    \\n    results = ANALYSIS_RESULTS\\n    safe_uni_name = results['university'].replace(' ', '_').replace('/', '_').replace(',', '')\\n    pdf_filename = f\\\"./output/{safe_uni_name}_Patent_Analysis_Report.pdf\\\"\\n    \\n    print(f\\\"üìÑ Generating PDF report: {pdf_filename}\\\")\\n    \\n    # Create PDF document\\n    doc = SimpleDocTemplate(pdf_filename, pagesize=A4)\\n    story = []\\n    styles = getSampleStyleSheet()\\n    \\n    # Custom styles\\n    title_style = ParagraphStyle(\\n        'CustomTitle',\\n        parent=styles['Heading1'],\\n        fontSize=18,\\n        spaceAfter=30,\\n        alignment=TA_CENTER,\\n        textColor=colors.HexColor('#2E86AB')\\n    )\\n    \\n    heading_style = ParagraphStyle(\\n        'CustomHeading',\\n        parent=styles['Heading2'],\\n        fontSize=14,\\n        spaceAfter=12,\\n        textColor=colors.HexColor('#A23B72')\\n    )\\n    \\n    subheading_style = ParagraphStyle(\\n        'CustomSubHeading',\\n        parent=styles['Heading3'],\\n        fontSize=12,\\n        spaceAfter=6,\\n        textColor=colors.HexColor('#F18F01')\\n    )\\n    \\n    # Title Page\\n    story.append(Spacer(1, 1*inch))\\n    story.append(Paragraph(f\\\"{results['university']}\\\", title_style))\\n    story.append(Paragraph(\\\"Comprehensive Patent Portfolio Analysis\\\", styles['Heading2']))\\n    story.append(Spacer(1, 0.5*inch))\\n    story.append(Paragraph(f\\\"Analysis Period: {results['filing_period']}\\\", styles['Normal']))\\n    story.append(Paragraph(f\\\"Report Generated: {datetime.now().strftime('%B %d, %Y')}\\\", styles['Normal']))\\n    story.append(Paragraph(f\\\"Patents Analyzed: {results['analyzed_patents']}\\\", styles['Normal']))\\n    story.append(Spacer(1, 0.3*inch))\\n    story.append(Paragraph(\\\"Generated by DeepTechFinder University Analysis Platform\\\", styles['Italic']))\\n    story.append(PageBreak())\\n    \\n    # Executive Summary\\n    story.append(Paragraph(\\\"Executive Summary\\\", title_style))\\n    \\n    # Key metrics calculations\\n    success_rate = results['success_count'] / results['analyzed_patents'] * 100 if results['analyzed_patents'] > 0 else 0\\n    priority_rate = len(results['priority_patents']) / results['success_count'] * 100 if results['success_count'] > 0 else 0\\n    collab_patents = len([p for p in results['patents'] if len(p['applicants']) > 1])\\n    collab_rate = collab_patents / results['success_count'] * 100 if results['success_count'] > 0 else 0\\n    \\n    summary_data = [\\n        ['Metric', 'Value', 'Assessment'],\\n        ['Total Applications (DTF)', str(results['total_applications']), 'Portfolio Scale'],\\n        ['Granted Patents Available', str(results['granted_patents']), 'Grant Success'],\\n        ['Patents Analyzed', str(results['analyzed_patents']), 'Sample Size'],\\n        ['EPO OPS Success Rate', f\\\"{success_rate:.1f}%\\\", 'Data Quality'],\\n        ['Filing Period', results['filing_period'], 'Innovation Timeline'],\\n        ['Unique Applicants', str(len(results['all_applicants'])), 'Collaboration Breadth'],\\n        ['Industry Partners', str(len(results['industry_collaborators'])), 'Industry Engagement'],\\n        ['Collaboration Rate', f\\\"{collab_rate:.1f}%\\\", 'Partnership Strategy'],\\n        ['German Priority Rate', f\\\"{priority_rate:.1f}%\\\", 'Filing Strategy'],\\n        ['Unique Inventors', str(len(results['all_inventors'])), 'Research Network']\\n    ]\\n    \\n    summary_table = Table(summary_data)\\n    summary_table.setStyle(TableStyle([\\n        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#2E86AB')),\\n        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\\n        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\\n        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\\n        ('FONTSIZE', (0, 0), (-1, 0), 12),\\n        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\\n        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),\\n        ('GRID', (0, 0), (-1, -1), 1, colors.black)\\n    ]))\\n    \\n    story.append(summary_table)\\n    story.append(Spacer(1, 0.3*inch))\\n    \\n    # Strategic Assessment\\n    story.append(Paragraph(\\\"Strategic Assessment\\\", subheading_style))\\n    \\n    if collab_rate > 70:\\n        collab_assessment = \\\"Highly collaborative university with exceptional industry engagement\\\"\\n    elif collab_rate > 40:\\n        collab_assessment = \\\"Balanced collaboration approach with significant industry partnerships\\\"\\n    else:\\n        collab_assessment = \\\"University-focused strategy with selective industry collaboration\\\"\\n    \\n    if priority_rate > 70:\\n        strategy_assessment = \\\"Systematic German filing strategy demonstrating professional IP management\\\"\\n    elif priority_rate > 40:\\n        strategy_assessment = \\\"Balanced filing approach with significant domestic foundation\\\"\\n    else:\\n        strategy_assessment = \\\"Direct European filing strategy with immediate market focus\\\"\\n    \\n    story.append(Paragraph(f\\\"<b>Collaboration Strategy:</b> {collab_assessment}\\\", styles['Normal']))\\n    story.append(Paragraph(f\\\"<b>Filing Strategy:</b> {strategy_assessment}\\\", styles['Normal']))\\n    story.append(PageBreak())\\n    \\n    # Industry Collaboration Analysis\\n    if results['industry_collaborators']:\\n        story.append(Paragraph(\\\"Industry Collaboration Analysis\\\", heading_style))\\n        \\n        # Partner categorization (simplified for PDF)\\n        collaboration_categories = {\\n            'Chemical & Materials': ['BASF', 'BAYER', 'MERCK', 'CHEMICAL', 'MATERIALS'],\\n            'Research Institutes': ['FRAUNHOFER', 'MAX-PLANCK', 'HELMHOLTZ', 'INSTITUT'],\\n            'Technology & IT': ['SOFTWARE', 'TECHNOLOGY', 'DIGITAL', 'ELECTRONICS'],\\n            'Medical & Biotech': ['MEDICAL', 'BIOTECH', 'PHARMA', 'HEALTH'],\\n            'Automotive': ['BMW', 'MERCEDES', 'VOLKSWAGEN', 'BOSCH', 'AUTOMOTIVE'],\\n            'Energy & Environment': ['ENERGY', 'SOLAR', 'ENVIRONMENT', 'POWER']\\n        }\\n        \\n        partner_data = [['Category', 'Partners', 'Count']]\\n        uncategorized = list(results['industry_collaborators'])\\n        \\n        for category, keywords in collaboration_categories.items():\\n            category_partners = []\\n            for partner in list(uncategorized):\\n                if any(keyword in partner.upper() for keyword in keywords):\\n                    category_partners.append(partner)\\n                    uncategorized.remove(partner)\\n            \\n            if category_partners:\\n                partner_names = ', '.join(category_partners[:3])\\n                if len(category_partners) > 3:\\n                    partner_names += f\\\" (+{len(category_partners)-3} more)\\\"\\n                partner_data.append([category, partner_names, str(len(category_partners))])\\n        \\n        if uncategorized:\\n            other_names = ', '.join(uncategorized[:3])\\n            if len(uncategorized) > 3:\\n                other_names += f\\\" (+{len(uncategorized)-3} more)\\\"\\n            partner_data.append(['Other Industries', other_names, str(len(uncategorized))])\\n        \\n        partner_table = Table(partner_data, colWidths=[1.5*inch, 3.5*inch, 0.8*inch])\\n        partner_table.setStyle(TableStyle([\\n            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#A23B72')),\\n            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\\n            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\\n            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\\n            ('FONTSIZE', (0, 0), (-1, 0), 10),\\n            ('FONTSIZE', (0, 1), (-1, -1), 9),\\n            ('BACKGROUND', (0, 1), (-1, -1), colors.lightgrey),\\n            ('GRID', (0, 0), (-1, -1), 1, colors.black),\\n            ('VALIGN', (0, 0), (-1, -1), 'TOP')\\n        ]))\\n        \\n        story.append(partner_table)\\n        story.append(Spacer(1, 0.2*inch))\\n    \\n    # Priority Family Analysis\\n    if results['priority_patents']:\\n        story.append(Paragraph(\\\"German Priority Family Analysis\\\", heading_style))\\n        \\n        priority_data = [\\n            ['German Priority', 'EP Patent', 'Filing Interval', 'Partners']\\n        ]\\n        \\n        # Add sample priority relationships\\n        sample_priorities = results['priority_patents'][:10]\\n        for priority_info in sample_priorities:\\n            german_priority = priority_info['german_priority']\\n            ep_patent = priority_info['ep_patent']\\n            applicants = priority_info['applicants']\\n            \\n            # Calculate interval\\n            priority_year = german_priority.split('¬∑')[1][:4] if '¬∑' in german_priority else 'N/A'\\n            ep_filing_year = 'N/A'\\n            for patent in results['patents']:\\n                if patent['ep_patent'] == ep_patent:\\n                    ep_filing_year = str(patent['filing_year'])\\n                    break\\n            \\n            if priority_year != 'N/A' and ep_filing_year != 'N/A':\\n                interval = int(ep_filing_year) - int(priority_year)\\n                interval_str = f\\\"{interval}y\\\" if interval > 0 else \\\"Same year\\\"\\n            else:\\n                interval_str = \\\"N/A\\\"\\n            \\n            # Partner summary\\n            university_terms = ['university', 'universit√§t', 'technische', 'hochschule']\\n            industry_partners = [app for app in applicants if not any(term in app.lower() for term in university_terms)]\\n            partner_str = f\\\"{len(industry_partners)} partners\\\" if industry_partners else \\\"University only\\\"\\n            \\n            priority_data.append([\\n                german_priority.split('¬∑')[0] if '¬∑' in german_priority else german_priority,\\n                ep_patent,\\n                interval_str,\\n                partner_str\\n            ])\\n        \\n        priority_table = Table(priority_data, colWidths=[1.8*inch, 1.5*inch, 1*inch, 1.5*inch])\\n        priority_table.setStyle(TableStyle([\\n            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#F18F01')),\\n            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\\n            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\\n            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\\n            ('FONTSIZE', (0, 0), (-1, 0), 9),\\n            ('FONTSIZE', (0, 1), (-1, -1), 8),\\n            ('BACKGROUND', (0, 1), (-1, -1), colors.lightblue),\\n            ('GRID', (0, 0), (-1, -1), 1, colors.black)\\n        ]))\\n        \\n        story.append(priority_table)\\n        story.append(Spacer(1, 0.2*inch))\\n    \\n    # Technology Portfolio Sample\\n    story.append(Paragraph(\\\"Technology Portfolio Sample\\\", heading_style))\\n    \\n    sample_patents = results['patents'][:5]\\n    for i, patent in enumerate(sample_patents, 1):\\n        story.append(Paragraph(f\\\"<b>Patent {i}: {patent['ep_patent']} ({patent['filing_year']})</b>\\\", subheading_style))\\n        \\n        title_text = patent['title'][:100] + \\\"...\\\" if patent['title'] and len(patent['title']) > 100 else patent['title'] or \\\"N/A\\\"\\n        story.append(Paragraph(f\\\"<b>Title:</b> {title_text}\\\", styles['Normal']))\\n        \\n        applicant_text = ', '.join(patent['applicants'][:3])\\n        if len(patent['applicants']) > 3:\\n            applicant_text += f\\\" (+{len(patent['applicants'])-3} more)\\\"\\n        story.append(Paragraph(f\\\"<b>Applicants:</b> {applicant_text}\\\", styles['Normal']))\\n        \\n        inventor_text = ', '.join(patent['inventors'][:3])\\n        if len(patent['inventors']) > 3:\\n            inventor_text += f\\\" (+{len(patent['inventors'])-3} more)\\\"\\n        story.append(Paragraph(f\\\"<b>Inventors:</b> {inventor_text}\\\", styles['Normal']))\\n        \\n        if patent['priority_claims']:\\n            story.append(Paragraph(f\\\"<b>Priority:</b> {patent['priority_claims'][0]}\\\", styles['Normal']))\\n        \\n        if patent['ipc_classes']:\\n            ipc_text = ', '.join(patent['ipc_classes'][:5])\\n            story.append(Paragraph(f\\\"<b>IPC Classes:</b> {ipc_text}\\\", styles['Normal']))\\n        \\n        story.append(Spacer(1, 0.1*inch))\\n    \\n    # Footer\\n    story.append(PageBreak())\\n    story.append(Paragraph(\\\"Analysis Methodology\\\", heading_style))\\n    story.append(Paragraph(\\n        \\\"This analysis was generated using the DeepTechFinder University Analysis Platform, \\\"\\n        \\\"which integrates EPO's DeepTechFinder data with real-time EPO OPS API bibliographic enrichment. \\\"\\n        \\\"The methodology is based on proven analytical frameworks validated with major German universities including \\\"\\n        \\\"TU Dresden and demonstrates 100% EPO OPS retrieval success rates for comprehensive patent intelligence.\\\",\\n        styles['Normal']\\n    ))\\n    \\n    story.append(Spacer(1, 0.2*inch))\\n    story.append(Paragraph(\\n        \\\"<b>Data Sources:</b> EPO DeepTechFinder, EPO Open Patent Services (OPS) API<br/>\\\"\\n        \\\"<b>Analysis Engine:</b> Custom Python application with interactive Jupyter interface<br/>\\\"\\n        \\\"<b>Rate Limiting:</b> EPO OPS compliant with 2-second intervals between requests<br/>\\\"\\n        \\\"<b>Data Quality:</b> Complete bibliographic enrichment with applicant, inventor, and classification data\\\",\\n        styles['Normal']\\n    ))\\n    \\n    # Build PDF\\n    doc.build(story)\\n    \\n    print(f\\\"‚úÖ PDF report generated successfully: {pdf_filename}\\\")\\n    print(f\\\"üìÑ Report includes:\\\")\\n    print(f\\\"   ‚Ä¢ Executive summary with key metrics\\\")\\n    print(f\\\"   ‚Ä¢ Industry collaboration analysis\\\")\\n    print(f\\\"   ‚Ä¢ Priority family relationships\\\")\\n    print(f\\\"   ‚Ä¢ Technology portfolio samples\\\")\\n    print(f\\\"   ‚Ä¢ Strategic assessment and insights\\\")\\n    \\n    return pdf_filename\\n\\n# Generate PDF if requested\\nif 'ANALYSIS_RESULTS' in globals() and 'CREATE_PDF' in globals() and CREATE_PDF:\\n    pdf_file = generate_pdf_report()\\nelse:\\n    print(\\\"‚ÑπÔ∏è  To generate PDF report:\\\")\\n    print(\\\"   1. Complete the analysis above\\\")\\n    print(\\\"   2. Enable 'Generate PDF Report' option\\\")\\n    print(\\\"   3. Re-run the analysis\\\")\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\\n\\n### Analysis Complete! üéâ\\n\\nYou have successfully completed a comprehensive patent analysis using the DeepTechFinder University Analysis Platform. \\n\\n### What You've Accomplished:\\n\\n‚úÖ **Interactive University Selection** - Explored 100 German universities with advanced sorting and filtering\\n\\n‚úÖ **Real-time EPO OPS Integration** - Retrieved complete bibliographic data with proven 100% success rates\\n\\n‚úÖ **Comprehensive Analysis** - Industry collaborations, priority families, inventor networks, and strategic insights\\n\\n‚úÖ **Professional Exports** - CSV datasets and PDF reports ready for stakeholder sharing\\n\\n‚úÖ **Validated Methodology** - Based on proven frameworks from TU Dresden and HTW Saarland analyses\\n\\n### Available Outputs:\\n\\nüìä **CSV Data Files** (in ./output/ directory):\\n- `{university}_complete_analysis.csv` - Full patent dataset with all fields\\n- `{university}_applicants.csv` - Applicant directory with categorization\\n- `{university}_inventors.csv` - Inventor network with proper normalization\\n- `{university}_german_priorities.csv` - Priority family relationships\\n\\nüìÑ **PDF Report** (if enabled):\\n- `{university}_Patent_Analysis_Report.pdf` - Professional analysis document\\n\\n### Next Steps for Patent Professionals:\\n\\nüîç **Enhanced Due Diligence** - Use complete applicant data for comprehensive FTO analysis\\n\\nü§ù **Partnership Intelligence** - Leverage industry collaboration mapping for business development\\n\\nüá©üá™ **Family Analysis** - Utilize priority relationships for complete patent family understanding\\n\\nüìà **Portfolio Strategy** - Apply insights to technology transfer and IP management decisions\\n\\nüîÑ **Scaling Analysis** - Adapt methodology for additional universities or larger patent datasets\\n\\n### Technical Notes:\\n\\n- **Rate Limiting**: EPO OPS compliant with 2-second intervals\\n- **Data Quality**: Complete bibliographic enrichment with deduplication\\n- **Methodology**: Extensible framework for systematic patent intelligence\\n- **Performance**: Optimized for both small samples and large-scale analysis\\n\\n---\\n\\n**Need to analyze another university?** Simply select a new university in the widgets above and re-run the analysis!\\n\\n**Questions or customizations?** This platform demonstrates the power of combining DeepTechFinder data with EPO OPS enrichment for comprehensive patent intelligence.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
