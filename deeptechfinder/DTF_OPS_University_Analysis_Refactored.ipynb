{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepTechFinder University Patent Analysis Platform\n",
    "\n",
    "## Interactive Analysis of German University Patent Portfolios\n",
    "\n",
    "This comprehensive notebook provides an **interactive analysis platform** for exploring German university patent portfolios using EPO's DeepTechFinder data enriched with detailed bibliographic information from EPO OPS API.\n",
    "\n",
    "### Key Features\n",
    "- **Interactive University Selection** - Choose from 100 German universities with sortable options\n",
    "- **Comprehensive Patent Analysis** - Complete bibliographic data enrichment via EPO OPS\n",
    "- **Advanced Collaboration Mapping** - Industry partnerships and research networks\n",
    "- **Priority Patent Family Analysis** - Strategic filing patterns and family relationships\n",
    "- **Professional PDF Reports** - Export-ready analysis documents\n",
    "- **CSV Data Exports** - Complete datasets for further analysis\n",
    "\n",
    "### Coverage\n",
    "- **100 German Universities** with 11,118 total patent applications\n",
    "- **4,907 granted patents** analyzed across all institutions\n",
    "- **1.8M+ students** represented across the university system\n",
    "- **Real-time EPO OPS integration** for up-to-date patent intelligence\n",
    "\n",
    "### Target Users\n",
    "- **Patent Information Professionals** - Enhanced due diligence and FTO analysis\n",
    "- **PATLIB Staff** - University patent portfolio intelligence\n",
    "- **Technology Transfer Offices** - Strategic partnership identification\n",
    "- **Research Institutions** - Competitive analysis and collaboration opportunities\n",
    "- **Patent Attorneys** - Comprehensive prior art and inventor network mapping\n",
    "\n",
    "### Methodology Validation\n",
    "Based on proven analysis frameworks demonstrated with **TU Dresden** (265 patents) and **University of Applied Sciences Saarbrücken** portfolios, with **100% EPO OPS retrieval success rates** and **complete bibliographic enrichment**.\n",
    "\n",
    "---\n",
    "\n",
    "**Ready to explore German university innovation? Start with Part 1 below.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 1: University Selection Interface\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell loads all necessary Python libraries for the analysis\n",
    "- pandas for data manipulation\n",
    "- requests for API calls\n",
    "- base64 for authentication encoding\n",
    "- time for rate limiting\n",
    "- json for data parsing\n",
    "- os for file operations\n",
    "- datetime for timestamps\n",
    "- numpy for numerical operations\n",
    "- re for text pattern matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Loading German University Patent Data...\n",
      "✅ Loaded data for 100 German universities\n",
      "📈 Total students: 1,789,466\n",
      "📄 Total applications: 11,118\n",
      "🏆 Total granted patents: 4,907\n",
      "🎯 University data loaded successfully!\n",
      "\n",
      "✅ Setup complete\n"
     ]
    }
   ],
   "source": [
    "# Simple setup with all necessary imports\n",
    "import pandas as pd\n",
    "import requests\n",
    "import base64\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "# Load university data and create interactive selector\n",
    "print(\"📊 Loading German University Patent Data...\")\n",
    "\n",
    "# Load university statistics from pre-processed data\n",
    "try:\n",
    "    with open('./output/university_analysis.json', 'r') as f:\n",
    "        university_data = json.load(f)\n",
    "    \n",
    "    # Get universities list and create sorted versions\n",
    "    universities_list = university_data['universities']\n",
    "    \n",
    "    # Create different sorting options\n",
    "    universities_by_applications = sorted(universities_list, key=lambda x: x['total_applications'], reverse=True)\n",
    "    universities_by_students = sorted(universities_list, key=lambda x: x['total_students'], reverse=True)\n",
    "    universities_by_granted = sorted(universities_list, key=lambda x: x['granted_patents'], reverse=True)\n",
    "    universities_by_grant_rate = sorted(universities_list, key=lambda x: x['grant_rate'], reverse=True)\n",
    "    universities_alphabetical = sorted(universities_list, key=lambda x: x['name'])\n",
    "    \n",
    "    # Store all sorting options for widget use\n",
    "    university_data_sorted = {\n",
    "        'by_applications': universities_by_applications,\n",
    "        'by_students': universities_by_students,\n",
    "        'by_granted': universities_by_granted,\n",
    "        'by_grant_rate': universities_by_grant_rate,\n",
    "        'alphabetical': universities_alphabetical\n",
    "    }\n",
    "    \n",
    "    universities_sorted = universities_by_applications  # Default to applications sorting\n",
    "    \n",
    "    print(f\"✅ Loaded data for {len(universities_sorted)} German universities\")\n",
    "    print(f\"📈 Total students: {sum(u['total_students'] for u in universities_sorted):,}\")\n",
    "    print(f\"📄 Total applications: {sum(u['total_applications'] for u in universities_sorted):,}\")\n",
    "    print(f\"🏆 Total granted patents: {sum(u['granted_patents'] for u in universities_sorted):,}\")\n",
    "    \n",
    "    # Create university selection options\n",
    "    university_options = [(f\"{u['name']} ({u['total_applications']} patents, {u['total_students']:,} students)\", u['name']) \n",
    "                         for u in universities_sorted]\n",
    "    \n",
    "    print(\"🎯 University data loaded successfully!\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"❌ University data not found. Please run university analysis first.\")\n",
    "    print(\"💡 Run: python ./scripts/analyze_universities.py\")\n",
    "    university_options = []\n",
    "except KeyError as e:\n",
    "    print(f\"❌ Unexpected data structure in university_analysis.json: {e}\")\n",
    "    print(\"💡 The file may need to be regenerated with: python ./scripts/analyze_universities.py\")\n",
    "    university_options = []\n",
    "\n",
    "\n",
    "print(\"\\n✅ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell loads the patent data from the CSV file\n",
    "- Tries UTF-8 encoding first, then falls back to Latin-1 if needed\n",
    "- Shows total number of records and universities\n",
    "- Displays the top 10 universities by patent count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Load the DeepTechFinder data with proper encoding handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 11118 records with latin-1\n",
      "Columns: ['University', 'Total_number_of_Spin_outs', 'Spin_outs_List', 'Total_students', 'Total_number_of_applications', 'Application_title', 'Espacenet_link', 'Filing_year', 'Patent_status', 'Technical_field']\n",
      "Universities: 100\n",
      "\n",
      "📊 Top 10 Universities by Patent Count:\n",
      "  Karlsruhe Institute of Technology: 1269 patents\n",
      "  Technical University of Munich: 647 patents\n",
      "  University of Erlangen-Nrnberg: 553 patents\n",
      "  University of Freiburg: 537 patents\n",
      "  Technische Universitt Dresden: 492 patents\n",
      "  Heidelberg University: 420 patents\n",
      "  Technical University of Berlin: 388 patents\n",
      "  Aachen University: 351 patents\n",
      "  Johannes Gutenberg University Mainz: 333 patents\n",
      "  Ludwig Maximilian University of Munich: 307 patents\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('data/EPO_DeepTechFinder_20250513_DE_Uni_Top100.csv', encoding='utf-8')\n",
    "    print(f\"✅ Loaded {len(df)} records\")\n",
    "except:\n",
    "    try:\n",
    "        df = pd.read_csv('data/EPO_DeepTechFinder_20250513_DE_Uni_Top100.csv', encoding='latin-1')\n",
    "        print(f\"✅ Loaded {len(df)} records with latin-1\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"Universities: {df['University'].nunique()}\")\n",
    "\n",
    "# Display top universities by patent count\n",
    "uni_counts = df['University'].value_counts().head(10)\n",
    "print(\"\\n📊 Top 10 Universities by Patent Count:\")\n",
    "for uni, count in uni_counts.items():\n",
    "    print(f\"  {uni}: {count} patents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell selects a specific university and filters for granted patents\n",
    "- Choose a university from the dataset\n",
    "- Filter for EP granted patents only\n",
    "- Take a sample (default 10) for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "University: Karlsruhe Institute of Technology\n",
      "Total patents: 1269\n",
      "Granted patents: 811\n",
      "\n",
      "Analyzing sample of: 10 patents\n"
     ]
    }
   ],
   "source": [
    "# Select a university for analysis\n",
    "university = \"Karlsruhe Institute of Technology\"  # Change this to analyze different universities\n",
    "uni_data = df[df['University'] == university]\n",
    "granted = uni_data[uni_data['Patent_status'] == 'EP granted']\n",
    "\n",
    "print(f\"University: {university}\")\n",
    "print(f\"Total patents: {len(uni_data)}\")\n",
    "print(f\"Granted patents: {len(granted)}\")\n",
    "\n",
    "# Take a sample for analysis (adjust size as needed)\n",
    "sample_size = 10  # Change this to analyze more patents\n",
    "sample = granted.head(sample_size)\n",
    "print(f\"\\nAnalyzing sample of: {len(sample)} patents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell creates a simple EPO OPS client class\n",
    "- Loads credentials from the .env file\n",
    "- Handles OAuth token generation\n",
    "- Provides a method to retrieve patent data from EPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Credentials loaded\n"
     ]
    }
   ],
   "source": [
    "# Simple EPO OPS client\n",
    "class SimpleOPSClient:\n",
    "    def __init__(self):\n",
    "        # Load credentials\n",
    "        with open('../ipc-ops/.env', 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                if line.startswith('OPS_KEY='):\n",
    "                    self.key = line.split('=')[1].strip()\n",
    "                elif line.startswith('OPS_SECRET='):\n",
    "                    self.secret = line.split('=')[1].strip()\n",
    "        \n",
    "        self.token = None\n",
    "        print(f\"✅ Credentials loaded\")\n",
    "    \n",
    "    def get_token(self):\n",
    "        if self.token:\n",
    "            return self.token\n",
    "            \n",
    "        url = \"https://ops.epo.org/3.2/auth/accesstoken\"\n",
    "        credentials = f\"{self.key}:{self.secret}\"\n",
    "        encoded = base64.b64encode(credentials.encode()).decode()\n",
    "        \n",
    "        headers = {\n",
    "            'Authorization': f'Basic {encoded}',\n",
    "            'Content-Type': 'application/x-www-form-urlencoded'\n",
    "        }\n",
    "        \n",
    "        response = requests.post(url, headers=headers, data={'grant_type': 'client_credentials'})\n",
    "        if response.status_code == 200:\n",
    "            self.token = response.json()['access_token']\n",
    "            print(\"✅ Token obtained\")\n",
    "            return self.token\n",
    "        else:\n",
    "            print(f\"❌ Token error: {response.status_code}\")\n",
    "            return None\n",
    "    \n",
    "    def get_patent(self, ep_number):\n",
    "        if not self.get_token():\n",
    "            return None\n",
    "            \n",
    "        # Clean number\n",
    "        clean_num = ep_number.replace('EP', '').replace('A', '').replace('B', '')\n",
    "        \n",
    "        url = f\"https://ops.epo.org/3.2/rest-services/published-data/application/epodoc/EP{clean_num}/biblio\"\n",
    "        headers = {\n",
    "            'Authorization': f'Bearer {self.token}',\n",
    "            'Accept': 'application/json'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "ops = SimpleOPSClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell tests the EPO OPS connection with one patent\n",
    "- Extracts EP number from the Espacenet link\n",
    "- Calls EPO OPS API to retrieve bibliographic data\n",
    "- Confirms that the connection is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Test with one patent\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m test_row \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m ep_link \u001b[38;5;241m=\u001b[39m test_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEspacenet_link\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m ep_number \u001b[38;5;241m=\u001b[39m ep_link\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq=\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample' is not defined"
     ]
    }
   ],
   "source": [
    "# Test with one patent\n",
    "test_row = sample.iloc[0]\n",
    "ep_link = test_row['Espacenet_link']\n",
    "ep_number = ep_link.split('q=')[1]\n",
    "\n",
    "print(f\"Testing: {ep_number}\")\n",
    "\n",
    "result = ops.get_patent(ep_number)\n",
    "if result:\n",
    "    print(\"✅ EPO OPS working\")\n",
    "    print(f\"Data keys: {list(result.keys())[:5]}...\")\n",
    "else:\n",
    "    print(\"❌ EPO OPS failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell processes multiple patents and extracts key data\n",
    "- Loops through the sample patents\n",
    "- Retrieves data from EPO OPS for each patent\n",
    "- Extracts title, applicants, inventors, and priority claims\n",
    "- Implements rate limiting (2 seconds between requests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function to extract data from OPS response\n",
    "def extract_data(ops_response):\n",
    "    \"\"\"Extract key information from OPS response\"\"\"\n",
    "    extracted = {\n",
    "        'title': 'N/A',\n",
    "        'applicants': [],\n",
    "        'inventors': [],\n",
    "        'priority_claims': []\n",
    "    }\n",
    "    \n",
    "    if not ops_response:\n",
    "        return extracted\n",
    "    \n",
    "    # Navigate through the nested JSON structure\n",
    "    try:\n",
    "        # Find exchange documents\n",
    "        exchange_docs = ops_response.get('ops:world-patent-data', {}).get('exchange-documents', {})\n",
    "        exchange_doc = exchange_docs.get('exchange-document', {})\n",
    "        \n",
    "        # Handle if it's a list\n",
    "        if isinstance(exchange_doc, list):\n",
    "            exchange_doc = exchange_doc[0]\n",
    "        \n",
    "        biblio_data = exchange_doc.get('bibliographic-data', {})\n",
    "        \n",
    "        # Extract title\n",
    "        titles = biblio_data.get('invention-title', [])\n",
    "        if isinstance(titles, list):\n",
    "            for title in titles:\n",
    "                if isinstance(title, dict) and title.get('@lang') == 'en':\n",
    "                    extracted['title'] = title.get('$', 'N/A')\n",
    "                    break\n",
    "            if extracted['title'] == 'N/A' and titles:\n",
    "                # Use first available title\n",
    "                first_title = titles[0] if isinstance(titles, list) else titles\n",
    "                if isinstance(first_title, dict):\n",
    "                    extracted['title'] = first_title.get('$', 'N/A')\n",
    "        elif isinstance(titles, dict):\n",
    "            extracted['title'] = titles.get('$', 'N/A')\n",
    "        \n",
    "        # Extract applicants\n",
    "        parties = biblio_data.get('parties', {})\n",
    "        applicants = parties.get('applicants', {}).get('applicant', [])\n",
    "        if not isinstance(applicants, list):\n",
    "            applicants = [applicants]\n",
    "        \n",
    "        for applicant in applicants:\n",
    "            if isinstance(applicant, dict):\n",
    "                applicant_data = applicant.get('applicant-name', {})\n",
    "                if isinstance(applicant_data, dict):\n",
    "                    name = applicant_data.get('name', {}).get('$', 'Unknown')\n",
    "                    if name != 'Unknown':\n",
    "                        extracted['applicants'].append(name)\n",
    "        \n",
    "        # Extract inventors\n",
    "        inventors = parties.get('inventors', {}).get('inventor', [])\n",
    "        if not isinstance(inventors, list):\n",
    "            inventors = [inventors]\n",
    "        \n",
    "        for inventor in inventors:\n",
    "            if isinstance(inventor, dict):\n",
    "                inventor_data = inventor.get('inventor-name', {})\n",
    "                if isinstance(inventor_data, dict):\n",
    "                    name = inventor_data.get('name', {}).get('$', 'Unknown')\n",
    "                    if name != 'Unknown':\n",
    "                        extracted['inventors'].append(name)\n",
    "        \n",
    "        # Extract priority claims\n",
    "        priority_claims = biblio_data.get('priority-claims', {}).get('priority-claim', [])\n",
    "        if not isinstance(priority_claims, list):\n",
    "            priority_claims = [priority_claims]\n",
    "        \n",
    "        for claim in priority_claims:\n",
    "            if isinstance(claim, dict):\n",
    "                doc_id = claim.get('document-id', {})\n",
    "                if isinstance(doc_id, dict):\n",
    "                    country = doc_id.get('country', {}).get('$', '')\n",
    "                    doc_number = doc_id.get('doc-number', {}).get('$', '')\n",
    "                    date = doc_id.get('date', {}).get('$', '')\n",
    "                    if country and doc_number:\n",
    "                        priority_str = f\"{country}{doc_number}\"\n",
    "                        if date:\n",
    "                            priority_str += f\"·{date}\"\n",
    "                        extracted['priority_claims'].append(priority_str)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting data: {e}\")\n",
    "    \n",
    "    return extracted\n",
    "\n",
    "# Process the sample patents\n",
    "results = []\n",
    "\n",
    "print(\"Processing patents...\")\n",
    "for idx, row in sample.iterrows():\n",
    "    ep_link = row['Espacenet_link']\n",
    "    ep_number = ep_link.split('q=')[1]\n",
    "    \n",
    "    print(f\"\\n[{idx+1}/{len(sample)}] {ep_number}\")\n",
    "    \n",
    "    # Get patent data\n",
    "    data = ops.get_patent(ep_number)\n",
    "    \n",
    "    if data:\n",
    "        # Extract information\n",
    "        extracted = extract_data(data)\n",
    "        \n",
    "        result = {\n",
    "            'ep_number': ep_number,\n",
    "            'title': extracted['title'][:100] + '...' if len(extracted['title']) > 100 else extracted['title'],\n",
    "            'year': row['Filing_year'],\n",
    "            'applicants': extracted['applicants'],\n",
    "            'inventors': extracted['inventors'],\n",
    "            'priority_claims': extracted['priority_claims'],\n",
    "            'num_applicants': len(extracted['applicants']),\n",
    "            'num_inventors': len(extracted['inventors']),\n",
    "            'has_priority': len(extracted['priority_claims']) > 0\n",
    "        }\n",
    "        results.append(result)\n",
    "        \n",
    "        print(f\"  ✅ Title: {result['title']}\")\n",
    "        print(f\"  👥 Applicants: {result['num_applicants']}\")\n",
    "        print(f\"  🔬 Inventors: {result['num_inventors']}\")\n",
    "        print(f\"  📋 Priority claims: {len(extracted['priority_claims'])}\")\n",
    "    else:\n",
    "        results.append({\n",
    "            'ep_number': ep_number,\n",
    "            'title': row['Application_title'],\n",
    "            'year': row['Filing_year'],\n",
    "            'applicants': [],\n",
    "            'inventors': [],\n",
    "            'priority_claims': [],\n",
    "            'num_applicants': 0,\n",
    "            'num_inventors': 0,\n",
    "            'has_priority': False\n",
    "        })\n",
    "        print(\"  ❌ Failed to retrieve data\")\n",
    "    \n",
    "    # Rate limiting\n",
    "    time.sleep(2)\n",
    "\n",
    "print(f\"\\n✅ Processed {len(results)} patents\")\n",
    "success_rate = len([r for r in results if r['num_applicants'] > 0]) / len(results) * 100\n",
    "print(f\"Success rate: {success_rate:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell analyzes the results and generates summary statistics\n",
    "- Counts unique applicants and inventors\n",
    "- Identifies industry collaborators\n",
    "- Analyzes German priority filings\n",
    "- Calculates collaboration rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the results\n",
    "all_applicants = set()\n",
    "all_inventors = set()\n",
    "industry_partners = set()\n",
    "german_priorities = []\n",
    "\n",
    "# University keywords to identify academic institutions\n",
    "university_terms = ['university', 'universität', 'technische', 'hochschule', 'institut']\n",
    "\n",
    "for result in results:\n",
    "    # Collect applicants\n",
    "    for applicant in result['applicants']:\n",
    "        all_applicants.add(applicant)\n",
    "        \n",
    "        # Check if it's an industry partner\n",
    "        if not any(term in applicant.lower() for term in university_terms):\n",
    "            industry_partners.add(applicant)\n",
    "    \n",
    "    # Collect inventors\n",
    "    for inventor in result['inventors']:\n",
    "        all_inventors.add(inventor)\n",
    "    \n",
    "    # Collect German priorities\n",
    "    for priority in result['priority_claims']:\n",
    "        if priority.startswith('DE'):\n",
    "            german_priorities.append({\n",
    "                'ep_number': result['ep_number'],\n",
    "                'priority': priority\n",
    "            })\n",
    "\n",
    "# Calculate statistics\n",
    "collaborative_patents = len([r for r in results if r['num_applicants'] > 1])\n",
    "patents_with_priority = len([r for r in results if r['has_priority']])\n",
    "\n",
    "print(\"📊 ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"University: {university}\")\n",
    "print(f\"Patents analyzed: {len(results)}\")\n",
    "print(f\"Successful retrievals: {len([r for r in results if r['num_applicants'] > 0])}\")\n",
    "print()\n",
    "print(f\"👥 COLLABORATION METRICS:\")\n",
    "print(f\"  • Unique applicants: {len(all_applicants)}\")\n",
    "print(f\"  • Industry partners: {len(industry_partners)}\")\n",
    "print(f\"  • Unique inventors: {len(all_inventors)}\")\n",
    "print(f\"  • Collaborative patents: {collaborative_patents}/{len(results)} ({collaborative_patents/len(results)*100:.1f}%)\")\n",
    "print()\n",
    "print(f\"📋 FILING STRATEGY:\")\n",
    "print(f\"  • Patents with priority claims: {patents_with_priority}/{len(results)} ({patents_with_priority/len(results)*100:.1f}%)\")\n",
    "print(f\"  • German priorities: {len(german_priorities)}\")\n",
    "\n",
    "# Show top industry partners\n",
    "if industry_partners:\n",
    "    print(f\"\\n🏢 TOP INDUSTRY PARTNERS:\")\n",
    "    for i, partner in enumerate(sorted(industry_partners)[:5], 1):\n",
    "        print(f\"  {i}. {partner}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell saves the analysis results to CSV files\n",
    "- Complete analysis with all patent details\n",
    "- List of unique applicants\n",
    "- List of unique inventors  \n",
    "- German priority relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV files\n",
    "safe_uni_name = university.replace(' ', '_').replace('/', '_').replace(',', '')\n",
    "\n",
    "# 1. Complete analysis\n",
    "results_df = pd.DataFrame(results)\n",
    "complete_file = f'output/{safe_uni_name}_complete_analysis.csv'\n",
    "results_df.to_csv(complete_file, index=False)\n",
    "print(f\"✅ Complete analysis saved to: {complete_file}\")\n",
    "\n",
    "# 2. Applicants list\n",
    "if all_applicants:\n",
    "    applicants_df = pd.DataFrame({\n",
    "        'applicant': sorted(all_applicants),\n",
    "        'type': ['Industry' if not any(term in app.lower() for term in university_terms) else 'University' \n",
    "                 for app in sorted(all_applicants)]\n",
    "    })\n",
    "    applicants_file = f'output/{safe_uni_name}_applicants.csv'\n",
    "    applicants_df.to_csv(applicants_file, index=False)\n",
    "    print(f\"✅ Applicants saved to: {applicants_file}\")\n",
    "\n",
    "# 3. Inventors list\n",
    "if all_inventors:\n",
    "    inventors_df = pd.DataFrame({'inventor': sorted(all_inventors)})\n",
    "    inventors_file = f'output/{safe_uni_name}_inventors.csv'\n",
    "    inventors_df.to_csv(inventors_file, index=False)\n",
    "    print(f\"✅ Inventors saved to: {inventors_file}\")\n",
    "\n",
    "# 4. German priorities\n",
    "if german_priorities:\n",
    "    priorities_df = pd.DataFrame(german_priorities)\n",
    "    priorities_file = f'output/{safe_uni_name}_german_priorities.csv'\n",
    "    priorities_df.to_csv(priorities_file, index=False)\n",
    "    print(f\"✅ German priorities saved to: {priorities_file}\")\n",
    "\n",
    "print(\"\\n🎯 Analysis complete! All results saved to output/ directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
